# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/201_data.annotated.ipynb (unless otherwise specified).

__all__ = ['preprocess_extract_annotation_windows', 'TSAnnotatedTensor', 'TSAnnotatedDataset', 'TSAnnotatedDatasets',
           'TSAnnotatedDataLoader', 'TSAnnotatedDataLoaders', 'pre_categorize', 'get_ats_dl', 'get_ats_dls',
           'TSPerAnnotationGenericClassifier', 'TSPerAnnClassification', 'TSPerAnnMultiLabelClassification',
           'TSAnnotationWindow', 'get_ats_dls_with_transforms']

# Cell
from ..imports import *
from ..utils import *
from .external import *
from .core import *
from .preprocessing import *

# Cell
from .synthetic import get_synthetic_sin_data

# Internal Cell
def _sliding_annotations(all_ann, lengths, width=100, offset=None, limit=None, include_empty=False):
    lengths = [lengths]*len(all_ann) if isinstance(lengths, int) else lengths   # lengths for each row
    offset = offset if offset else -width//2
    offsetR = width + offset
    for i, row_anns in enumerate(all_ann):
        row_anns =  [(idx, e) for idx, e in enumerate(row_anns)
                     if e+offset >=0 and e+offsetR <  lengths[i]]  # trim overlap
        if len(row_anns) > 0:
            if limit and len(row_anns) > limit:
                random.shuffle(row_anns)
                row_anns = row_anns[:limit]
            for i_a, pos in row_anns:
                yield i, pos+offset, pos+offsetR, i_a
        elif include_empty:
            pos = random.randint(lengths[i]-width)
            yield i, pos, pos+width, None
        else:
            continue

# Internal Cell
def _compute_new_splits(m, orig_splits):
    return L( L(i for i, old_i in enumerate(m) if old_i in split_set)
              for split_set in orig_splits)

# Internal Cell
def _compute_new_folds(m, orig_folds):
    return orig_folds[m]

# Cell
@delegates(_sliding_annotations)
def preprocess_extract_annotation_windows(X, anns, y=None, splits=None, folds=None,
                                          per_ann_label=False, verbose=False, **kwargs):
    """Extracted timeseries subsequences and optionally label relative to annotated positions"""
    lengths = [x.shape[-1] for x in X]

    if isinstance(y, NoneType):
        if verbose: print('No Label')
        X_win, m = zip(*[[X[i_orig][..., idx_l:idx_r], i_orig]
            for (i_orig, idx_l, idx_r, _) in _sliding_annotations(anns, lengths, **kwargs)])
        y_win = None
    elif per_ann_label:
        if verbose: print('label per annotation')
        X_win, y_win, m = zip(*[[X[i_orig][..., idx_l:idx_r], y[i_orig][i_a], i_orig]
            for (i_orig, idx_l, idx_r, i_a) in _sliding_annotations(anns, lengths, **kwargs)])
        y_win = L(*y_win)
    elif isinstance(y[0], np.ndarray):
        if verbose: print('label is vector')
        assert y[0].shape[-1] == X[0].shape[-1]
        X_win, y_win, m = zip(*[[X[i_orig][..., idx_l:idx_r], y[i_orig][idx_l:idx_r], i_orig]
            for (i_orig, idx_l, idx_r, _) in _sliding_annotations(anns, lengths, **kwargs)])
        y_win = np.array(y_win)
    else:
        if verbose: print('label per row')
        X_win, y_win, m = zip(*[[X[i_orig][..., idx_l:idx_r], y[i_orig], i_orig]
            for (i_orig, idx_l, idx_r, _) in _sliding_annotations(anns, lengths, **kwargs)])
        y_win = L(*y_win)

    ret = [np.array(X_win)]
    if not isinstance(y_win, NoneType):
        ret.append(y_win)

    if not isinstance(splits, NoneType):
        return *ret, _compute_new_splits(m, splits)
    elif not isinstance(folds, NoneType):
        return *ret, _compute_new_folds(m, folds)
    elif len(ret) == 1:
        return ret[0]
    else:
        return ret

# Cell
class TSAnnotatedTensor(TSTensor):
    """Extends TSTensor to include a set of per-timeseries event annotations"""
    @delegates(TSTensor.__init__)
    def __init__(self, *args, ann=[], **kwargs):
        """Initializes TSAnnotatedTensor using X, y and list of annotations"""
        if len(args) >= 1 and not isinstance(args[0], (np.ndarray, NumpyTensor, torch.Tensor,
                                                       TSTensor, TSAnnotatedTensor)):
            raise Exception(f'TSAnnotatedTensor does not support X value of type {type(args[0])}')
        TSTensor.__init__(*args, **kwargs)
        self.ann = ann

    def __repr__(self):
        if self.numel() == 1: return f'{self}'
        elif self.ndim >= 3:
            return f'TSAnnotatedTensor(rows:{self.shape[-3]}, vars:{self.shape[-2]}, len:{self.shape[-1]}, ann:{len(self.ann)})'
        elif self.ndim == 2:
            return f'TSAnnotatedTensor(vars:{self.shape[-2]}, len:{self.shape[-1]}, ann:{len(self.ann)})'
        elif self.ndim == 1:
            return f'TSAnnotatedTensor(len:{self.shape[-1]}, ann:{len(self.ann)})'


    def show(self, show_ann=True, ann_y_val=None, ann_color='r', ann_size=None, *args, **kwargs):
        """Shows plot of timeseries with annotations"""
        ax =  super().show(*args, **kwargs)
        if show_ann and len(self.ann) > 0:
            x = self.data[0][0].cpu() if len(self.data.size()) == 3 else self.data[0] if len(self.data.size()) == 2 else self.data
            ann = self.ann[0] if len(self.data.size()) == 3 else self.ann
            if ann_y_val is None:
                ax.scatter(ann, x[ann], c=ann_color, s=ann_size)
            else:
                ax.scatter(ann, [ann_y_val]*len(ann), c=ann_color, s=ann_size)
        return ax

# Cell
#@delegates(TSDataset.__init__)
class TSAnnotatedDataset(TSDataset):
    """Extends TSDataset to include a set of per-timeseries event annotations,
    X value of type TSAnnotatedTensor"""
    #@delegates(TSDataset.__init__)
    def __init__(self, *args, anns=None, **kwargs):
        """Extends TSDataset to include a set of per-timeseries event annotations,
        X value of type TSAnnotatedTensor"""
        super().__init__(*args, **kwargs)
        assert self.types is None or self.types[0] == TSAnnotatedTensor
        self.anns = anns

    def __getitem__(self, idx):
        #a = [] if self.anns is None else self.anns[idx] if isinstance(idx, int) else [self.anns[i] for i in idx]
        a = [] if self.anns is None else self.anns[idx]
        _x = TSAnnotatedTensor(self.X[idx, self.sel_vars, self.sel_steps], ann=a)
        if self.y is not None:
            y = self.y[idx] if isinstance(idx, int) else [self.y[i] for i in idx]

        if self.types is None or self.y is None:
            return (_x, y) if self.y is not None else (_x)
        else:
            return (_x, self.types[1](y)) if self.y is not None else (_x)

    def __repr__(self):
        _y = y.shape if isinstance(self.y, (Tensor, np.ndarray)) else len(self.y) if self.y else None
        _a = len(self.anns) if self.anns else None
        return f'TSAnnotatedDataset(X:{self.X.shape}, y:{_y}, anns:{_a})'

# Cell
class TSAnnotatedDatasets(TSDatasets):
    """Extends TSDatasets to include a set of per-timeseries event annotations"""
    _xtype, _ytype = TSAnnotatedTensor, None # Expected X  (torch.Tensor subclass) and y output (L or torch.Tensor subclass)
    @delegates(TSDatasets.__init__)
    def __init__(self, X=None, y=None, anns=None, items=None, sel_vars=None, sel_steps=None, tfms=None, tls=None, n_inp=None, dl_type=None,
                 inplace=True, **kwargs):
        """Extends TSDatasets to include a set of per-timeseries event annotations,
        X value of type TSAnnotatedTensor"""
        if X is not None and not isinstance(X, (np.ndarray, torch.Tensor)): X = np.asarray(X)
        if y is not None and not isinstance(y, (np.ndarray, torch.Tensor, L)): y = L(*y)
        self.anns = anns
        self.inplace = inplace
        if tls is None:
            X = itemify(to3darray(X), tup_id=0)
            y = itemify(y, tup_id=0) if isinstance(y, (np.ndarray, torch.Tensor)) else y
            items = tuple((X,)) if y is None else tuple((X,y))
            self.tfms = L(ifnone(tfms,[None]*len(ifnone(tls,items))))
        self.sel_vars = ifnone(sel_vars, slice(None))
        self.sel_steps = ifnone(sel_steps,slice(None))
        self.tls = L(tls if tls else [TfmdLists(item, t, **kwargs) for item,t in zip(items,self.tfms)])
        self.n_inp = (1 if len(self.tls)==1 else len(self.tls)-1) if n_inp is None else n_inp
        if 'split' in kwargs: self.split_idxs = kwargs['split']
        elif 'splits' in kwargs:  self.split_idxs = kwargs['splits']
        else: self.split_idxs = L(np.arange(len(self.tls[0]) if len(self.tls[0]) > 0 else len(self.tls)).tolist())
        if len(self.tls[0]) > 0:
            self.types = L(ifnone(self._xtype, type(self.tls[0][0])))
            if len(self.tls) > 1:
                self.types.append(tensor if isinstance(self.tls[1][0], np.ndarray) else type(self.tls[1][0]))
            self.ptls = L([tl if not self.inplace
                           else tl[:] if type(tl[0]).__name__ == 'memmap'
                           else tl if not isinstance(tl[0], (np.ndarray, torch.Tensor))
                           else tensor(stack(tl[:]))
                           for tl in self.tls])


    def __getitem__(self, it):
        assert self.types[0] == TSAnnotatedTensor
        a = [] if self.anns is None else self.anns[it]
        _x = TSAnnotatedTensor(self.ptls[0][it, self.sel_vars, self.sel_steps], ann=a)
        if len(self.ptls)> 1 and self.ptls[1] is not None:
            _y = self.types[1](self.ptls[1][it])
            return tuple([_x, _y])
        else:
            return tuple([_x])

    def __repr__(self):
        n_per = len(self.tls)
        n_tot = len(self.split_idxs) if isinstance(self.split_idxs[0], int) else len(self.tls[0])
        n_sets = 1 if isinstance(self.split_idxs[0], int) else len(self.split_idxs)
        if n_sets > 1 and isinstance(self.split_idxs[0], (L, list, tuple)):
            n_train = len(self.split_idxs[0]) if n_sets>0 else 0
            n_valid = len(self.split_idxs[1]) if n_sets>1 else 0
            n_test = len(self.split_idxs[2]) if n_sets>2 else 0
            return f'TSAnnotatedDatasets(rows:{n_tot}, columns:{n_per}, sets:{n_sets}, train:{n_train}, valid:{n_valid}, test:{n_test})'
        else:
            return f'TSAnnotatedDatasets(rows:{n_tot}, columns:{n_per}, sets:{n_sets} - unsplit)'


    def subset(self, i):
        return type(self)(tls=L(tl.subset(i) for tl in self.tls),
                          n_inp=self.n_inp, inplace=self.inplace, tfms=self.tfms,
                          sel_vars=self.sel_vars, sel_steps=self.sel_steps,
                          split=L(self.splits[i]) if self.splits is not None else None,
                          anns = (self.anns[self.split_idxs[i]]
                                 if self.anns and len(self.anns) >= i
                                 and self.split_idxs and len(self.split_idxs) >= i
                                 else self.anns))

# Cell
class TSAnnotatedDataLoader(TSDataLoader):
    pass

# Cell
class TSAnnotatedDataLoaders(TSDataLoaders):
    #_xblock = TSAnnotatedTensorBlock
    _dl_type = TSAnnotatedDataLoader

# Cell
def pre_categorize(*args, categorizer=None, splits=None, default=None):
    """Applies categorizer to list or nest list of labels.  Used
    to preprocess per-annotation labels"""
    is_nested = isinstance(args[0][0], (tuple, list, L))
    if categorizer is None: categorizer=Categorize
    if inspect.isclass(categorizer):
        y_train = args[0][splits[0]] if splits else args[0]
        vocab = {y_per for y_row in y_train for y_per in y_row} \
                if is_nested else {y_row for y_row in y_train}
        if default: vocab.add(default)
        c = categorizer()
        c.setups(vocab)
    else:
        c = categorizer
    if is_nested:
        results = [[[c(y_per) for y_per in y_row] for y_row in y_set] for y_set in args]
    else:
        results = [[c(y_row) for y_row in y_set] for y_set in args]
    results = results[0] if len(args) == 1 else results
    return results, c

# Cell
def get_ats_dl(X, y=None, anns=None, sel_vars=None, sel_steps=None, tfms=None, inplace=True,
            path='.', bs=64, batch_tfms=None, num_workers=0, device=None, shuffle_train=True, drop_last=True, **kwargs):
    """Creates singla dataloader from annotated timeseries data"""
    splits = (L(np.arange(len(X)).tolist()), L([]))
    dsets = TSAnnotatedDatasets(X, y, anns=anns, splits=splits, sel_vars=sel_vars, sel_steps=sel_steps, tfms=tfms, inplace=inplace, **kwargs)
    dls   = TSAnnotatedDataLoaders.from_dsets(dsets.train, path=path, bs=bs, batch_tfms=batch_tfms, num_workers=num_workers,
                                     device=device, shuffle_train=shuffle_train, drop_last=drop_last, **kwargs)
    return dls.train

# Cell
def get_ats_dls(X, y=None, anns=None, splits=None, sel_vars=None, sel_steps=None, tfms=None, inplace=True,
            path='.', bs=64, batch_tfms=None, num_workers=0, device=None, shuffle_train=True, drop_last=True, **kwargs):
    """Creats dataloaders for annotated timeseries data"""
    if splits is None: splits = (L(np.arange(len(X)).tolist()), L([]))
    dsets = TSAnnotatedDatasets(X, y, anns=anns, splits=splits, sel_vars=sel_vars, sel_steps=sel_steps, tfms=tfms, inplace=inplace)
    dls   = TSAnnotatedDataLoaders.from_dsets(dsets.train, dsets.valid, path=path, bs=bs, batch_tfms=batch_tfms, num_workers=num_workers,
                                     device=device, shuffle_train=shuffle_train, drop_last=drop_last, **kwargs)
    return dls

# Cell
class TSPerAnnotationGenericClassifier(DisplayedTransform):
    """Common base class supporting slassification of list of Labels"""
    def __init__(self, classifier, default=None, **kwargs):
        assert classifier is not None
        self.classifier = classifier(**kwargs) if inspect.isclass(classifier) else classifier
        self.default=default

    @property
    def vocab(self):
        """Returns vocabulary with map"""
        return self.classifier.vocab

    @property
    def internal_classifier(self):
        """Returns underlying classifier (TSClassification or TSMultiLabelClassification)"""
        return self.classifier

    def setups(self, dsets):
        if self.classifier.vocab is None and dsets is not None:
            label_values = [label for row in dsets for label in row]
            if self.default: label_values.append(label_values)
            self.classifier.setups(label_values)

    def encodes(self, o):
        return L(self.classifier.encodes(oo) for oo in o)

    def decodes(self, o):
        return L(self.classifier.decodes(oo) for oo in o)

# Cell
class TSPerAnnClassification(TSPerAnnotationGenericClassifier):
    """Classifies list of per-annotation labels, returns L(TensorCategory)"""
    @delegates(TSPerAnnotationGenericClassifier.__init__)
    @delegates(TSClassification.__init__)
    def __init__(self, **kwargs):
        """Classifies list of per-annotation labels, returns L(TensorCategory)"""
        super().__init__(TSClassification, **kwargs)

# Cell
class TSPerAnnMultiLabelClassification(TSPerAnnotationGenericClassifier):
    """Classifies list of per-annotation multi-labels,
    returns (L(tensor) contining one-hot encoded values"""
    @delegates(ItemTransform.__init__)
    @delegates(TSMultiLabelClassification.__init__)
    def __init__(self, **kwargs):
        """Classifies list of per-annotation multi-labels,
        returns (L(tensor) contining one-hot encoded values"""
        super().__init__(TSMultiLabelClassification, **kwargs)

# Cell
class TSAnnotationWindow(ItemTransform):
    """Extract subsequence corresponding to annotation and selects appropriate label"""
    @delegates(ItemTransform.__init__)
    def __init__(self, width=100, offset=None, x_out_type=None, y_out_type=None,
                 default_label=None, verbose=False, classifier=None, **kwargs):
        """Extract subsequence corresponding to annotation and selects appropriate label"""
        self.width, self.offset, self.verbose = width, offset, verbose
        self.x_out_type, self.y_out_type, self.default_label = x_out_type, y_out_type, default_label
        self.y_mode, self.classifier = None, classifier
        super().__init__(**kwargs)


    def _setup(self, o):
        o_x, o_y = o
        self.is_batch =  len(o_x.data.shape) == 3 and o_x.data.shape[0] > 1
        if self.is_batch:
            o_y = o_y[0]  # loot at first row of y values when assessing type

        if isinstance(o_y, (TensorCategory, TensorMultiCategory)):
            self.y_mode = 'common'
        elif isinstance(o_y, (TSTensor, Tensor)):
            self.y_mode = 'tensor'
            if not self.y_out_type and isinstance(o_y, TSTensor):
                self.y_out_type = TSTensor
        elif isinstance(o_y, np.ndarray):
            self.y_mode = 'numpy'
            if not self.y_out_type:
                self.y_out_type = TSTensor
        elif isinstance(o_y, (list, tuple, L)):
            self.y_mode = 'per_ann'
        else:
            raise Exception(f'Unknown y type: {type(o_y)}')
        if self.x_out_type is None:
            self.x_out_type = TSTensor


    def encodes(self, o):
        o_x, o_y = o
        if self.y_mode is None:
            self._setup(o)
        #o_y = L(*o_y) if isinstance(o_y, list) else o_y

        windows = [z for z in _sliding_annotations(o_x.ann, o_x.data.size()[-1], width=self.width,
                                              offset=self.offset, include_empty=True, limit=1)]
        output_x = torch.stack([o_x[i_row, :, idxL:idxR] for i_row, idxL, idxR, idx_a in windows] )
        output_x = self.x_out_type(output_x)

        if self.y_mode == 'common':
            output_y = o_y
        elif self.y_mode == 'tensor':
            output_y = torch.stack([o_y[i_row, ..., idxL:idxR]
                                    for i_row, idxL, idxR, idx_a in windows] )
            if self.y_out_type:
                output_y = self.y_out_type(output_y)
            elif isinstance(o_y, TSTensor):
                output_y = o_y.new(output_y)
        elif self.y_mode == 'numpy':
            output_y = np.vstack([o_y[i_row][..., idxL:idxR]
                                    for i_row, idxL, idxR, idx_a in windows] )
            if self.y_out_type:
                output_y = self.y_out_type(output_y)
            elif isinstance(o_y, TSTensor):
                output_y = o_y.new(output_y)
        elif self.y_mode == 'per_ann':
            default_label = self.classifier.encode(self.default_label) \
                            if self.classifier and self.default_label else None
            output_y =  [o_y[i_row][idx_a] if idx_a else default_label if default_label \
                         else o_y[i_row][idx_a]
                         for i_row, idxL, idxR, idx_a in windows]
        else:
            raise exception(f'unknown y_mode: {self.y_mode}')

        if self.y_mode in ('per_ann', 'common'):
            if self.y_out_type:
                output_y = self.y_out_type(output_y)
            else:
                output_y = output_y[0].new(output_y)

        return output_x, output_y

# Internal Cell
def _tfm_to_list(entry):
    if isinstance(entry, (tuple, list, L)):
        return list(*entry)
    elif entry:
        return [entry]
    else:
        return []

# Internal Cell
def _merge_transforms(prefix_tfms, existing_tfms):
    prefix_tfms = [_tfm_to_list(prefix_tfms[0]) , _tfm_to_list(prefix_tfms[1])] \
                   if prefix_tfms else [[], []]
    existing_tfms = [tfm_to_list(existing_tfms[0]) , tfm_to_list(existing_tfms[1])] \
                     if existing_tfms else [[], []]
    return [prefix_tfms[0]+existing_tfms[0], prefix_tfms[1]+existing_tfms[1]]

# Cell
@delegates(get_ats_dls)
def get_ats_dls_with_transforms(X, y=None, per_ann_label=False,
                                window_width=100, window_offset=None,
                                default_label=None,tfms=None, batch_tfms=None,
                                **kwargs):
    """Returns TSAnnotatedDataLoaders with pre-configured transforms based on
    label types.  Also includes classifier to decode/encode individual label"""
    is_vector = isinstance(y[0], (np.ndarray, Tensor))

    if is_vector:
        tfm_y = ToTSTensor
        classifier = None
    elif per_ann_label: # per_ann
        if isinstance(y[0][0], (tuple, list, L)): # multi-category
            tfm_y = TSPerAnnMultiLabelClassification(default=default_label)
        else:
            tfm_y = TSPerAnnClassification(default=default_label)
        classifier = tfm_y.internal_classifier
    else:   # per-row
        if isinstance(y[0], (tuple, list, L)): # multi-category
            tfm_y = TSMultiLabelClassification()
        else:
            tfm_y = TSClassification()
        classifier = tfm_y

    if per_ann_label and default_label:
        tsaw = TSAnnotationWindow(width=window_width, offset=window_offset,
                                  default_label=default_label,
                                  classifier=tfm_y.internal_classifier)
    else:
        tsaw = TSAnnotationWindow(width=window_width, offset=window_offset)

    tfms = _merge_transforms([None, tfm_y], tfms)
    batch_tfms = _tfm_to_list(tsaw) + _tfm_to_list(batch_tfms)
    dls = get_ats_dls(X, y=y, tfms=tfms, batch_tfms=batch_tfms, **kwargs)
    return dls, classifier