{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Tabular\n",
    "\n",
    "> Main Tabular functions used throughout the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *\n",
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')\n",
    "splits = RandomSplitter()(range_of(df))\n",
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "y_names = 'salary'\n",
    "y_block = CategoryBlock()\n",
    "pd.options.mode.chained_assignment=None\n",
    "to = TabularPandas(df, procs=procs, cat_names=cat_names, cont_names=cont_names,\n",
    "                   y_names=y_names, y_block=y_block, splits=splits, inplace=True,\n",
    "                   reduce_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TabularDataset():\n",
    "    \"A `Numpy` dataset from a `TabularPandas` object\"\n",
    "    def __init__(self, to):\n",
    "        self.cats = to.cats.to_numpy().astype(np.long)\n",
    "        self.conts = to.conts.to_numpy().astype(np.float32)\n",
    "        self.ys = to.ys.to_numpy()\n",
    "    def __getitem__(self, idx): return self.cats[idx], self.conts[idx], self.ys[idx]\n",
    "    def __len__(self): return len(self.cats)\n",
    "    @property\n",
    "    def c(self): return 0 if self.ys is None else 1 if isinstance(self.ys[0], float) else len(np.unique(self.ys))\n",
    "\n",
    "class TabularDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, bs=1, num_workers=0, device=None, train=False, **kwargs):\n",
    "        device = ifnone(device, default_device())\n",
    "        super().__init__(dataset, bs=min(bs, len(dataset)), num_workers=num_workers, shuffle=train, device=device, drop_last=train, **kwargs)\n",
    "        self.device, self.shuffle = device, train\n",
    "    def create_item(self, s): return s\n",
    "    def get_idxs(self):\n",
    "        idxs = Inf.count if self.indexed else Inf.nones\n",
    "        if self.n is not None: idxs = list(range(len(self.dataset)))\n",
    "        if self.shuffle: self.shuffle_fn()\n",
    "        return idxs\n",
    "    def create_batch(self, b):\n",
    "        return self.dataset[b[0]:b[0]+self.bs]\n",
    "    def shuffle_fn(self):\n",
    "        \"Shuffle dataset after each epoch\"\n",
    "        rng = np.random.permutation(len(self.dataset))\n",
    "        self.dataset.cats = self.dataset.cats[rng]\n",
    "        self.dataset.conts = self.dataset.conts[rng]\n",
    "        self.dataset.ys = self.dataset.ys[rng]\n",
    "    def to(self, device): \n",
    "        self.device = device\n",
    "#     def ds_to(self, device=None):\n",
    "        self.dataset.cats = tensor(self.dataset.cats).to(device=self.device)\n",
    "        self.dataset.conts = tensor(self.dataset.conts).to(device=self.device)\n",
    "        self.dataset.ys = tensor(self.dataset.ys).to(device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TabularDataset(to.train)\n",
    "valid_ds = TabularDataset(to.valid)\n",
    "train_dl = TabularDataLoader(train_ds, bs=512, train=True)\n",
    "valid_dl = TabularDataLoader(valid_ds, bs=512)\n",
    "dls = DataLoaders(train_dl,valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs = get_emb_sz(to)\n",
    "net = TabularModel(emb_szs, 3, 2, layers=[200,100])#.cuda()\n",
    "learn = Learner(dls, net, metrics=accuracy, loss_func=CrossEntropyLossFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.377850</td>\n",
       "      <td>0.364125</td>\n",
       "      <td>0.829238</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current notebook saved.\n",
      "\n",
      "Converted 000_utils.ipynb.\n",
      "Converted 001_data.external.ipynb.\n",
      "Converted 002_data.core.ipynb.\n",
      "Converted 003_data.transforms.ipynb.\n",
      "Converted 005_data.tabular.ipynb.\n",
      "Converted 006_data.validation.ipynb.\n",
      "Converted 007_metrics.ipynb.\n",
      "Converted 008_learner.ipynb.\n",
      "Converted 009_optimizers.ipynb.\n",
      "Converted 010_rocket_functions.ipynb.\n",
      "Converted 100_layers.ipynb.\n",
      "Converted 100b_models_utils.ipynb.\n",
      "Converted 101_ResNet.ipynb.\n",
      "Converted 102_InceptionTime.ipynb.\n",
      "Converted index.ipynb.\n",
      "\n",
      "Checking folder: /Users/nacho/Documents/Machine_Learning/Jupyter_Notebooks/timeseries/tsai\n",
      "Correct conversion! ðŸ˜ƒ\n",
      "Total elapsed time 13 s\n",
      "21-04-2020 15:29:32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,UklGRvQHAABXQVZFZm10IBAAAAABAAEAECcAACBOAAACABAAZGF0YdAHAAAAAP5/EhAGghzg+Hk2L/WLOMJIbGJLL502qMpX0WKetLiTyD0LdMrQCIbkH/p97u8CgAAA/n8SEAaCHOD4eTYv9Ys4wkhsYksvnTaoylfRYp60uJPIPQt0ytAIhuQf+n3u7wKAAAD+fxIQBoIc4Ph5Ni/1izjCSGxiSy+dNqjKV9FinrS4k8g9C3TK0AiG5B/6fe7vAoAAAP5/EhAGghzg+Hk2L/WLOMJIbGJLL502qMpX0WKetLiTyD0LdMrQCIbkH/p97u8CgAAA/n8SEAaCHOD4eTYv9Ys4wkhsYksvnTaoylfRYp60uJPIPQt0ytAIhuQf+n3u7wKAAAD+fxIQBoIc4Ph5Ni/1izjCSGxiSy+dNqjKV9FinrS4k8g9C3TK0AiG5B/6fe7vAoAAAP5/EhAGghzg+Hk2L/WLOMJIbGJLL502qMpX0WKetLiTyD0LdMrQCIbkH/p97u8CgAAA/n8SEAaCHOD4eTYv9Ys4wkhsYksvnTaoylfRYp60uJPIPQt0ytAIhuQf+n3u7wKAAAD+fxIQBoIc4Ph5Ni/1izjCSGxiSy+dNqjKV9FinrS4k8g9C3TK0AiG5B/6fe7vAoAAAP5/EhAGghzg+Hk2L/WLOMJIbGJLL502qMpX0WKetLiTyD0LdMrQCIbkH/p97u8CgAAA/n8SEAaCHOD4eTYv9Ys4wkhsYksvnTaoylfRYp60uJPIPQt0ytAIhuQf+n3u7wKAAAD+fxIQBoIc4Ph5Ni/1izjCSGxiSy+dNqjKV9FinrS4k8g9C3TK0AiG5B/6fe7vAoAAAP5/EhAGghzg+Hk2L/WLOMJIbGJLL502qMpX0WKetLiTyD0LdMrQCIbkH/p97u8CgAAA/n8SEAaCHOD4eTYv9Ys4wkhsYksvnTaoylfRYp60uJPIPQt0ytAIhuQf+n3u7wKAAAD+fxIQBoIc4Ph5Ni/1izjCSGxiSy+dNqjKV9FinrS4k8g9C3TK0AiG5B/6fe7vAoAAAP5/EhAGghzg+Hk2L/WLOMJIbGJLL502qMpX0WKetLiTyD0LdMrQCIbkH/p97u8CgAAA/n8SEAaCHOD4eTYv9Ys4wkhsYksvnTaoylfRYp60uJPIPQt0ytAIhuQf+n3u7wKAAAD+fxIQBoIc4Ph5Ni/1izjCSGxiSy+dNqjKV9FinrS4k8g9C3TK0AiG5B/6fe7vAoAAAP5/EhAGghzg+Hk2L/WLOMJIbGJLL502qMpX0WKetLiTyD0LdMrQCIbkH/p97u8CgAAA/n8SEAaCHOD4eTYv9Ys4wkhsYksvnTaoylfRYp60uJPIPQt0ytAIhuQf+n3u7wKAAAD+fxIQBoIc4Ph5Ni/1izjCSGxiSy+dNqjKV9FinrS4k8g9C3TK0AiG5B/6fe7vAoAAAP5/EhAGghzg+Hk2L/WLOMJIbGJLL502qMpX0WKetLiTyD0LdMrQCIbkH/p97u8CgAAA/n8SEAaCHOD4eTYv9Ys4wkhsYksvnTaoylfRYp60uJPIPQt0ytAIhuQf+n3u7wKAAAD+fxIQBoIc4Ph5Ni/1izjCSGxiSy+dNqjKV9FinrS4k8g9C3TK0AiG5B/6fe7vAoAAAP5/EhAGghzg+Hk2L/WLOMJIbGJLL502qMpX0WKetLiTyD0LdMrQCIbkH/p97u8CgAAA/n8SEAaCHOD4eTYv9Ys4wkhsYksvnTaoylfRYp60uJPIPQt0ytAIhuQf+n3u7wKAAAD+fxIQBoIc4Ph5Ni/1izjCSGxiSy+dNqjKV9FinrS4k8g9C3TK0AiG5B/6fe7vAoAAAP5/EhAGghzg+Hk2L/WLOMJIbGJLL502qMpX0WKetLiTyD0LdMrQCIbkH/p97u8CgAAA/n8SEAaCHOD4eTYv9Ys4wkhsYksvnTaoylfRYp60uJPIPQt0ytAIhuQf+n3u7wKAAAD+fxIQBoIc4Ph5Ni/1izjCSGxiSy+dNqjKV9FinrS4k8g9C3TK0AiG5B/6fe7vAoAAAP5/EhAGghzg+Hk2L/WLOMJIbGJLL502qMpX0WKetLiTyD0LdMrQCIbkH/p97u8BgAAA/n8SEAaCHOD4eTYv9Ys4wkhsYksvnTaoylfRYp60uJPIPQt0ytAIhuQf+n3u7wKAAAD+fxIQBoIc4Ph5Ni/1izjCSGxiSy+dNqjKV9FinrS4k8g9C3TK0AiG5B/6fe7vAoAAAP5/EhAGghzg+Hk2L/WLOMJIbGJLL502qMpX0WKetLiTyD0LdMrQCIbkH/p97u8CgAAA/n8SEAaCHOD4eTYv9Ys4wkhsYksvnTaoylfRYp60uJPIPQt0ytAIhuQf+n3u7wKAAAD+fxIQBoIc4Ph5Ni/1izjCSGxiSy+dNqjKV9FinrS4k8g9C3TK0AiG5B/6fe7vAoAAAP5/EhAGghzg+Hk2L/WLOMJIbGJLL502qMpX0WKetLiTyD0LdMrQCIbkH/p97u8CgAAA/n8SEAaCHOD4eTYv9Ys4wkhsYksvnTaoylfRYp60uJPIPQt0ytAIhuQf+n3u7wKAAAD+fxIQBoIc4Ph5Ni/1izjCSGxiSy+dNqjKV9FinrS4k8g9C3TK0AiG5B/6fe7vAoAAAP5/EhAGghzg+Hk2L/WLOMJIbGJLL502qMpX0WKetLiTyD0LdMrQCIbkH/p97u8CgA==\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "create_scripts()\n",
    "beep()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
