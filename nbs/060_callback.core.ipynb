{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp callback.core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callback\n",
    "\n",
    "> Miscellaneous callbacks for timeseriesAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from tsai.imports import *\n",
    "from tsai.utils import *\n",
    "from tsai.data.preprocessing import *\n",
    "from tsai.data.transforms import *\n",
    "from tsai.models.layers import *\n",
    "from fastai.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A callback can implement actions on the following events:\n",
    "* before_fit: called before doing anything, ideal for initial setup.\n",
    "* before_epoch: called at the beginning of each epoch, useful for any behavior you need to reset at each epoch.\n",
    "* before_train: called at the beginning of the training part of an epoch.\n",
    "* before_batch: called at the beginning of each batch, just after drawing said batch. It can be used to do any setup necessary for the batch (like hyper-parameter scheduling) or to change the input/target before it goes in the model (change of the input with techniques like mixup for instance).\n",
    "* after_pred: called after computing the output of the model on the batch. It can be used to change that output before it's fed to the loss.\n",
    "* after_loss: called after the loss has been computed, but before the backward pass. It can be used to add any penalty to the loss (AR or TAR in RNN training for instance).\n",
    "* before_backward: called after the loss has been computed, but only in training mode (i.e. when the backward pass will be used)\n",
    "* after_backward: called after the backward pass, but before the update of the parameters. It can be used to do any change to the gradients before said update (gradient clipping for instance).\n",
    "* after_step: called after the step and before the gradients are zeroed.\n",
    "* after_batch: called at the end of a batch, for any clean-up before the next one.\n",
    "* after_train: called at the end of the training phase of an epoch.\n",
    "* before_validate: called at the beginning of the validation phase of an epoch, useful for any setup needed specifically for validation.\n",
    "* after_validate: called at the end of the validation part of an epoch.\n",
    "* after_epoch: called at the end of an epoch, for any clean-up before the next one.\n",
    "* after_fit: called at the end of training, for final clean-up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing a callback, the following attributes of Learner are available:\n",
    "\n",
    "* **model**: the model used for training/validation\n",
    "* **data**: the underlying DataLoaders\n",
    "* **loss_func**: the loss function used\n",
    "* **opt**: the optimizer used to udpate the model parameters\n",
    "* **opt_func**: the function used to create the optimizer\n",
    "* **cbs**: the list containing all Callbacks\n",
    "* **dl**: current DataLoader used for iteration\n",
    "* **x/xb**: last input drawn from self.dl (potentially modified by callbacks). xb is always a tuple (potentially with one element) and x is detuplified. You can only assign to xb.\n",
    "* **y/yb**: last target drawn from self.dl (potentially modified by callbacks). yb is always a tuple (potentially with one element) and y is detuplified. You can only assign to yb.\n",
    "* **pred**: last predictions from self.model (potentially modified by callbacks)\n",
    "* **loss**: last computed loss (potentially modified by callbacks)\n",
    "* **n_epoch**: the number of epochs in this training\n",
    "* **n_iter**: the number of iterations in the current self.dl\n",
    "* **epoch**: the current epoch index (from 0 to n_epoch-1)\n",
    "* **iter**: the current iteration index in self.dl (from 0 to n_iter-1)\n",
    "\n",
    "The following attributes are added by TrainEvalCallback and should be available unless you went out of your way to remove that callback:\n",
    "* **train_iter**: the number of training iterations done since the beginning of this training\n",
    "* **pct_train**: from 0. to 1., the percentage of training iterations completed\n",
    "* **training**: flag to indicate if we're in training mode or not\n",
    "\n",
    "The following attribute is added by Recorder and should be available unless you went out of your way to remove that callback:\n",
    "* **smooth_loss**: an exponentially-averaged version of the training loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gambler's loss: noisy labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GamblersCallback(Callback):\n",
    "    \"A callback to use metrics with gambler's loss\"\n",
    "    def after_loss(self): self.learn.pred = self.learn.pred[..., :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.496496</td>\n",
       "      <td>1.540837</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tsai.data.all import *\n",
    "from tsai.models.InceptionTime import *\n",
    "from tsai.models.layers import *\n",
    "dsid = 'NATOPS'\n",
    "X, y, splits = get_UCR_data(dsid, return_split=False)\n",
    "tfms = [None, Categorize()]\n",
    "dsets = TSDatasets(X, y, tfms=tfms, splits=splits)\n",
    "dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128])\n",
    "loss_func = gambler_loss()\n",
    "learn = Learner(dls, InceptionTime(dls.vars, dls.c + 1), loss_func=loss_func, cbs=GamblersCallback, metrics=[accuracy])\n",
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TransformScheduler(Callback):\n",
    "    \"A callback to schedule batch transforms during training based on a function (sched_lin, sched_exp, sched_cos (default), etc)\"\n",
    "    def __init__(self, schedule_func:callable, show_plot:bool=False): \n",
    "        self.schedule_func,self.show_plot = schedule_func,show_plot\n",
    "        self.mult = []\n",
    "\n",
    "    def before_fit(self):\n",
    "        for pct in np.linspace(0, 1, len(self.dls.train) * self.n_epoch): self.mult.append(self.schedule_func(pct))\n",
    "        # get initial magnitude values and update initial value\n",
    "        self.mag = []\n",
    "        self.mag_tfms = []\n",
    "        for t in self.dls.after_batch: \n",
    "            if hasattr(t, 'magnitude'):\n",
    "                self.mag.append(t.magnitude)\n",
    "                t.magnitude *= self.mult[0]\n",
    "                self.mag_tfms.append(t)\n",
    "\n",
    "    def after_batch(self):\n",
    "        if self.training and len(self.mag_tfms)>0 and self.train_iter < len(self.mult):\n",
    "            # set values for next batch\n",
    "            for t,m in zip(self.mag_tfms, self.mag): \n",
    "                t.magnitude = m * self.mult[self.train_iter]\n",
    "                \n",
    "    def after_fit(self):\n",
    "        if self.show_plot and self.mult != [] and len(self.mag_tfms)>0: \n",
    "            print()\n",
    "            plt.plot(self.mult)\n",
    "            plt.title('Scheduled tfms')\n",
    "            plt.show()\n",
    "            print()\n",
    "            self.show_plot = False\n",
    "        # set values to initial values\n",
    "        for t,m in zip(self.mag_tfms, self.mag): t.magnitude = m\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}({self.schedule_func})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformScheduler(<fastai.callback.schedule._Annealer object at 0x7ff9b1152cc0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TransformScheduler(SchedCos(1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = torch.linspace(0.,1,100)\n",
    "f = combine_scheds([0.3, 0.4, 0.3], [SchedLin(1.,1.), SchedCos(1.,0.), SchedLin(0.,.0), ])\n",
    "plt.plot(p, [f(o) for o in p]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = torch.linspace(0.,1,100)\n",
    "f = combine_scheds([0.3, 0.7], [SchedCos(0.,1.), SchedCos(1.,0.)])\n",
    "plt.plot(p, [f(o) for o in p]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShowGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ShowGraph(Callback):\n",
    "    \"(Modified) Update a graph of training and validation loss\"\n",
    "    order,run_valid=65,False\n",
    "    names = ['train', 'valid']\n",
    "    def __init__(self, plot_metrics:bool=True, final_losses:bool=False):\n",
    "        store_attr(\"plot_metrics,final_losses\")\n",
    "\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.run = not hasattr(self.learn, 'lr_finder') and not hasattr(self, \"gather_preds\")\n",
    "        if not(self.run): return\n",
    "        self.nb_batches = []\n",
    "\n",
    "    def after_train(self): self.nb_batches.append(self.train_iter)\n",
    "\n",
    "    def after_epoch(self):\n",
    "        \"Plot validation loss in the pbar graph\"\n",
    "        if not self.nb_batches: return\n",
    "        rec = self.learn.recorder\n",
    "        iters = range_of(rec.losses)\n",
    "        val_pos = rec.metric_names.index('valid_loss') - 1\n",
    "        val_losses = [v[val_pos] for v in rec.values]\n",
    "        x_bounds = (0, (self.n_epoch - len(self.nb_batches)) * self.nb_batches[0] + len(rec.losses))\n",
    "        y_min = min((min(rec.losses), min(val_losses)))\n",
    "        y_max = max((max(rec.losses), max(val_losses)))\n",
    "        margin = (y_max - y_min) * .05\n",
    "        y_bounds = (y_min - margin, y_max + margin)\n",
    "        self.update_graph([(iters, rec.losses), (self.nb_batches, val_losses)], x_bounds, y_bounds)\n",
    "\n",
    "    def after_fit(self):\n",
    "        plt.close(self.graph_ax.figure)\n",
    "        if self.plot_metrics: self.learn.plot_metrics(final_losses=self.final_losses)\n",
    "\n",
    "    def update_graph(self, graphs, x_bounds=None, y_bounds=None, figsize=(6,4)):\n",
    "        if not hasattr(self, 'graph_fig'):\n",
    "            self.graph_fig, self.graph_ax = plt.subplots(1, figsize=figsize)\n",
    "            self.graph_out = display(self.graph_ax.figure, display_id=True)\n",
    "        self.graph_ax.clear()\n",
    "        if len(self.names) < len(graphs): self.names += [''] * (len(graphs) - len(self.names))\n",
    "        for g,n in zip(graphs,self.names): self.graph_ax.plot(*g, label=n)\n",
    "        self.graph_ax.legend(loc='upper right')\n",
    "        self.graph_ax.grid(color='gainsboro', linewidth=.5)\n",
    "        if x_bounds is not None: self.graph_ax.set_xlim(*x_bounds)\n",
    "        if y_bounds is not None: self.graph_ax.set_ylim(*y_bounds)\n",
    "        self.graph_ax.set_title(f'Losses\\nepoch: {self.epoch +1}/{self.n_epoch}')\n",
    "        self.graph_out.update(self.graph_ax.figure)        \n",
    "ShowGraphCallback2 = ShowGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SaveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class SaveModel(TrackerCallback):\n",
    "    \"A `TrackerCallback` that saves the model's best during training and loads it at the end with a verbose option.\"\n",
    "    _only_train_loop,order = True,TrackerCallback.order+1\n",
    "    def __init__(self, monitor='valid_loss', comp=None, min_delta=0., fname='model', every_epoch=False, at_end=False,\n",
    "                 with_opt=False, reset_on_fit=True, verbose=False):\n",
    "        super().__init__(monitor=monitor, comp=comp, min_delta=min_delta, reset_on_fit=reset_on_fit)\n",
    "        assert not (every_epoch and at_end), \"every_epoch and at_end cannot both be set to True\"\n",
    "        # keep track of file path for loggers\n",
    "        self.last_saved_path = None\n",
    "        store_attr('fname,every_epoch,at_end,with_opt,verbose')\n",
    "\n",
    "    def _save(self, name): self.last_saved_path = self.learn.save(name, with_opt=self.with_opt)\n",
    "\n",
    "    def after_epoch(self):\n",
    "        \"Compare the value monitored to its best score and save if best.\"\n",
    "        if self.every_epoch:\n",
    "            if (self.epoch%self.every_epoch) == 0: self._save(f'{self.fname}_{self.epoch}')\n",
    "        else: #every improvement\n",
    "            super().after_epoch()\n",
    "            if self.new_best:\n",
    "                pv(f'Better model found at epoch {self.epoch} with {self.monitor} value: {self.best}.', self.verbose)\n",
    "                self._save(f'{self.fname}')\n",
    "\n",
    "    def after_fit(self, **kwargs):\n",
    "        \"Load the best model.\"\n",
    "        if self.at_end: self._save(f'{self.fname}')\n",
    "        elif not self.every_epoch: self.learn.load(f'{self.fname}', with_opt=self.with_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty-based data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UBDAug(Callback):\n",
    "    r\"\"\"A callback to implement the uncertainty-based data augmentation.\"\"\"\n",
    "    \n",
    "    def __init__(self, batch_tfms:list, N:int=2, C:int=4, S:int=1): \n",
    "        r'''\n",
    "        Args:\n",
    "            batch_tfms:   list of available transforms applied to the combined batch. They will be applied in addition to the dl tfms.\n",
    "            N:            # composition steps (# transforms randomly applied to each sample)\n",
    "            C:            # augmented data per input data (# times N transforms are applied)\n",
    "            S:            # selected data points used for training (# augmented samples in the final batch from each original sample)\n",
    "        '''\n",
    "        \n",
    "        self.C, self.S = C, min(S, C)\n",
    "        self.batch_tfms = L(batch_tfms)\n",
    "        self.n_tfms = len(self.batch_tfms)\n",
    "        self.N = min(N, self.n_tfms)\n",
    "        \n",
    "    def before_fit(self):\n",
    "        assert hasattr(self.loss_func, 'reduction'), \"You need to pass a loss_function with a 'reduction' attribute\"\n",
    "        self.red = self.loss_func.reduction\n",
    "    \n",
    "    def before_batch(self):\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                setattr(self.loss_func, 'reduction', 'none')\n",
    "                for i in range(self.C):\n",
    "                    idxs = np.random.choice(self.n_tfms, self.N, False)\n",
    "                    x_tfm = compose_tfms(self.x, self.batch_tfms[idxs], split_idx=0)\n",
    "                    loss = self.loss_func(self.learn.model(x_tfm), self.y).reshape(-1,1)\n",
    "                    if i == 0:\n",
    "                        x2 = x_tfm.unsqueeze(1)\n",
    "                        max_loss = loss\n",
    "                    else: \n",
    "                        losses = torch.cat((max_loss, loss), dim=1)\n",
    "                        x2 = torch.cat((x2, x_tfm.unsqueeze(1)), dim=1)\n",
    "                        x2 = x2[np.arange(x2.shape[0]).reshape(-1,1), losses.argsort(1)[:, -self.S:]]\n",
    "                        max_loss = losses.max(1)[0].reshape(-1,1)\n",
    "                setattr(self.loss_func, 'reduction', self.red)\n",
    "            x2 = x2.reshape(-1, self.x.shape[-2], self.x.shape[-1])\n",
    "            if self.S > 1: self.learn.yb = (torch_tile(self.y, 2),)\n",
    "            self.learn.xb = (x2,)\n",
    "\n",
    "    def __repr__(self): return f'UBDAug({[get_tfm_name(t) for t in self.batch_tfms]})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.804918</td>\n",
       "      <td>1.782042</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tsai.data.all import *\n",
    "from tsai.models.all import *\n",
    "dsid = 'NATOPS'\n",
    "X, y, splits = get_UCR_data(dsid, return_split=False)\n",
    "tfms = [None, Categorize()]\n",
    "dsets = TSDatasets(X, y, tfms=tfms, splits=splits)\n",
    "dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, batch_tfms=[TSStandardize()])\n",
    "model = create_model(InceptionTime, dls=dls)\n",
    "TS_tfms = [TSMagScale(.75, p=.5), TSMagWarp(.1, p=0.5),  TSWindowWarp(.25, p=.5), \n",
    "           TSSmooth(p=0.5), TSRandomResizedCrop(.1, p=.5), \n",
    "           TSRandomCropPad(.3, p=0.5), \n",
    "           TSMagAddNoise(.5, p=.5)]\n",
    "\n",
    "ubda_cb = UBDAug(TS_tfms, N=2, C=4, S=2)\n",
    "learn = Learner(dls, model, cbs=ubda_cb, metrics=accuracy)\n",
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class WeightedPerSampleLoss(Callback):\n",
    "    order = 65\n",
    "\n",
    "    def __init__(self, instance_weights):\n",
    "        store_attr()\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.old_loss = self.learn.loss_func\n",
    "        self.reduction = getattr(self.learn.loss_func, 'reduction', None)\n",
    "        self.learn.loss_func = _PerInstanceLoss(crit=self.learn.loss_func)\n",
    "        assert len(self.instance_weights) == len(self.learn.dls.train.dataset) + len(self.learn.dls.valid.dataset)\n",
    "        self.instance_weights = torch.as_tensor(self.instance_weights, device=self.learn.dls.device)\n",
    "\n",
    "    def before_batch(self):\n",
    "        input_idxs = self.learn.dls.train.input_idxs if self.training else self.learn.dls.valid.input_idxs\n",
    "        self.learn.loss_func.weights = self.instance_weights[input_idxs]\n",
    "\n",
    "    def after_fit(self):\n",
    "        self.learn.loss_func = self.old_loss\n",
    "        if self.reduction is not None: self.learn.loss_func.reduction = self.reduction\n",
    "\n",
    "\n",
    "class _PerInstanceLoss(Module):\n",
    "    def __init__(self, crit):\n",
    "        self.crit = crit\n",
    "        self.crit.reduction = 'none'\n",
    "        self.weights = None\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return (self.crit(input, target) * self.weights / self.weights.sum()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class BatchSubsampler(Callback):\n",
    "    \"\"\" Callback that selects a percentage of samples and/ or sequence steps with replacement from each training batch\n",
    "\n",
    "    Args:\n",
    "    ====\n",
    "\n",
    "    sample_pct:     percentage of random samples (or instances) that will be drawn. If 1. the output batch will contain the same number of samples\n",
    "                    as the input batch.\n",
    "    step_pct:       percentage of random sequence steps that will be drawn. If 1. the output batch will contain the same number of sequence steps\n",
    "                    as the input batch. If used with models that don't use a pooling layer, this must be set to 1 to keep the same dimensions.\n",
    "                    With CNNs, this value may be different.\n",
    "    same_seq_len:   If True, it ensures that the output has the same shape as the input, even if the step_pct chosen is < 1. Defaults to True.\n",
    "    update_y:       used with step_pct. If True, it applies the same random indices to y. It can only be used with sequential targets.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sample_pct:Optional[float]=None, step_pct:Optional[float]=None, same_seq_len:bool=True, update_y:bool=False):\n",
    "        store_attr()\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.run = not hasattr(self, \"gather_preds\")\n",
    "        if not(self.run): return\n",
    "\n",
    "    def before_batch(self):\n",
    "        if not self.training: return\n",
    "\n",
    "        if self.sample_pct is not None:\n",
    "            B = self.x.shape[0]\n",
    "            if isinstance(self.sample_pct, tuple):\n",
    "                sample_pct = np.random.rand() * (self.sample_pct[1] - self.sample_pct[0]) + self.sample_pct[0]\n",
    "            else:\n",
    "                sample_pct = self.sample_pct\n",
    "            idxs = np.random.choice(B, round(B * sample_pct), True)\n",
    "            self.learn.xb = tuple(xbi[idxs] for xbi in self.learn.xb)\n",
    "            self.learn.yb = tuple(ybi[idxs] for ybi in self.learn.yb)\n",
    "\n",
    "        if self.step_pct is not None:\n",
    "            S = self.x.shape[-1]\n",
    "            if isinstance(self.step_pct, tuple):\n",
    "                step_pct = np.random.rand() * (self.step_pct[1] - self.step_pct[0]) + self.step_pct[0]\n",
    "            else:\n",
    "                step_pct = self.step_pct\n",
    "            if self.step_pct != 1 and self.same_seq_len:\n",
    "                idxs = np.sort(np.tile(np.random.choice(S, round(S * step_pct), True), math.ceil(1 / step_pct))[:S])\n",
    "            else:\n",
    "                idxs = np.sort(np.random.choice(S, round(S * step_pct), True))\n",
    "            self.learn.xb = tuple(xbi[...,idxs] for xbi in self.learn.xb)\n",
    "            if self.update_y:\n",
    "                self.learn.yb = tuple(ybi[...,idxs] for ybi in self.learn.yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BatchLossFilter(Callback):\n",
    "    \"\"\" Callback that selects the hardest samples in every batch representing a percentage of the total loss\"\"\"\n",
    "\n",
    "    def __init__(self, loss_perc=1., schedule_func:Optional[callable]=None):\n",
    "        store_attr()\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.run = not hasattr(self, \"gather_preds\")\n",
    "        if not(self.run): return\n",
    "        self.crit = self.learn.loss_func\n",
    "        if hasattr(self.crit, 'reduction'): self.red = self.crit.reduction\n",
    "\n",
    "    def before_batch(self):\n",
    "        if not self.training: return\n",
    "        if self.schedule_func is None: loss_perc = self.loss_perc\n",
    "        else: loss_perc = self.loss_perc * self.schedule_func(self.pct_train)\n",
    "        if loss_perc == 1.: return\n",
    "        with torch.no_grad():\n",
    "            if hasattr(self.crit, 'reduction'):  setattr(self.crit, 'reduction', 'none')\n",
    "            losses = self.crit(self.learn.model(self.x), self.y)\n",
    "            if losses.ndim == 2: losses = losses.mean(-1)\n",
    "            if hasattr(self.crit, 'reduction'):  setattr(self.crit, 'reduction', self.red)\n",
    "            losses /= losses.sum()\n",
    "            idxs = torch.argsort(losses, descending=True)\n",
    "            cut_idx = max(1, torch.argmax((losses[idxs].cumsum(0) > loss_perc).float()))\n",
    "            idxs = idxs[:cut_idx]\n",
    "            self.learn.xb = tuple(xbi[idxs] for xbi in self.learn.xb)\n",
    "            self.learn.yb = tuple(ybi[idxs] for ybi in self.learn.yb)\n",
    "\n",
    "    def after_fit(self):\n",
    "        if hasattr(self.learn.loss_func, 'reduction'):  setattr(self.learn.loss_func, 'reduction', self.red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class RandomWeightLossWrapper(Callback):\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.run = not hasattr(self, \"gather_preds\")\n",
    "        if not(self.run): return\n",
    "        self.crit = self.learn.loss_func\n",
    "        if hasattr(self.crit, 'reduction'): self.red = self.crit.reduction\n",
    "        self.learn.loss_func = self._random_weight_loss\n",
    "\n",
    "    def _random_weight_loss(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        if self.training:\n",
    "            setattr(self.crit, 'reduction', 'none')\n",
    "            loss = self.crit(input, target)\n",
    "            setattr(self.crit, 'reduction', self.red)\n",
    "            rw = torch.rand(input.shape[0], device=input.device)\n",
    "            rw /= rw.sum()\n",
    "            non_red_loss = loss * rw\n",
    "            return non_red_loss.sum()\n",
    "        else:\n",
    "            return self.crit(input, target)\n",
    "\n",
    "    def after_fit(self):\n",
    "        if hasattr(self.crit, 'reduction'): setattr(self.crit, 'reduction', self.red)\n",
    "        self.learn.loss_func = self.crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class SamplerWithReplacement(Callback):\n",
    "    \"\"\" Callback that selects a percentage of samples and/ or sequence steps with replacement from each training batch\"\"\"\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.run = not hasattr(self, \"gather_preds\")\n",
    "        if not(self.run): return\n",
    "\n",
    "        self.old_get_idxs = self.learn.dls.train.get_idxs\n",
    "        self.learn.dls.train.get_idxs = self._get_idxs\n",
    "\n",
    "    def _get_idxs(self):\n",
    "        dl = self.learn.dls.train\n",
    "        if dl.n==0: return []\n",
    "        if dl.weights is not None:\n",
    "            return np.random.choice(dl.n, dl.n, p=dl.weights)\n",
    "        idxs = Inf.count if dl.indexed else Inf.nones\n",
    "        if dl.n is not None: idxs = np.random.choice(dl.n,dl.n,True)\n",
    "        if dl.shuffle: idxs = dl.shuffle_fn(idxs)\n",
    "        return idxs\n",
    "\n",
    "    def after_fit(self):\n",
    "        self.learn.dls.train.get_idxs = self.old_get_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class BatchMasker(Callback):\n",
    "    \"\"\" Callback that applies a random mask to each sample in a training batch\n",
    "\n",
    "    Args:\n",
    "    ====\n",
    "    r:                  probability of masking.\n",
    "    subsequence_mask:   apply a mask to random subsequences.\n",
    "    lm:                 average mask len when using stateful (geometric) masking.\n",
    "    stateful:           geometric distribution is applied so that average mask length is lm.\n",
    "    sync:               all variables have the same masking.\n",
    "    variable_mask:      apply a mask to random variables. Only applicable to multivariate time series.\n",
    "    future_mask:        used to train a forecasting model.\n",
    "    schedule_func:      if a scheduler is passed, it will modify the probability of masking during training.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, r:float=.15, lm:int=3, stateful:bool=True, sync:bool=False, subsequence_mask:bool=True, \n",
    "                 variable_mask:bool=False, future_mask:bool=False, schedule_func:Optional[callable]=None):\n",
    "        store_attr()\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.run = not hasattr(self, \"gather_preds\")\n",
    "        if not(self.run): return\n",
    "\n",
    "    def before_batch(self):\n",
    "        if not self.training: return\n",
    "        r = self.r * self.schedule_func(self.pct_train) if self.schedule_func is not None else self.r\n",
    "        mask = create_mask(self.x,  r=r, lm=self.lm, stateful=self.stateful, sync=self.sync, \n",
    "                        subsequence_mask=self.subsequence_mask, variable_mask=self.variable_mask, future_mask=self.future_mask)\n",
    "        self.learn.xb = (self.xb[0].masked_fill(mask, 0),)\n",
    "        # In my tests, mask-based compensation doesn't seem to be important. ??\n",
    "        # mean_per_seq = (torch.max(torch.ones(1, device=mask.device), torch.sum(mask, dim=-1).unsqueeze(-1)) / mask.shape[-1])\n",
    "        # self.learn.xb = (self.xb[0].masked_fill(mask, 0) / (1 - mean_per_seq), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class SamplerWithReplacement(Callback):\n",
    "    \"\"\" Callback that modify the sampler to select a percentage of samples and/ or sequence steps with replacement from each training batch\"\"\"\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.run = not hasattr(self, \"gather_preds\")\n",
    "        if not(self.run): return\n",
    "\n",
    "        self.old_get_idxs = self.learn.dls.train.get_idxs\n",
    "        self.learn.dls.train.get_idxs = self._get_idxs\n",
    "\n",
    "    def _get_idxs(self):\n",
    "        dl = self.learn.dls.train\n",
    "        if dl.n==0: return []\n",
    "        if dl.weights is not None:\n",
    "            return np.random.choice(dl.n, dl.n, p=dl.weights)\n",
    "        idxs = Inf.count if dl.indexed else Inf.nones\n",
    "        if dl.n is not None: idxs = np.random.choice(dl.n,dl.n,True)\n",
    "        if dl.shuffle: idxs = dl.shuffle_fn(idxs)\n",
    "        return idxs\n",
    "\n",
    "    def after_fit(self):\n",
    "        self.learn.dls.train.get_idxs = self.old_get_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "060_callback.core.ipynb saved at 2021-11-02 09:36:03.\n",
      "Converted 060_callback.core.ipynb.\n",
      "\n",
      "\n",
      "Correct conversion! \n",
      "Total time elapsed 0.112 s\n",
      "Tuesday 02/11/21 09:36:06 CET\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "from tsai.imports import create_scripts\n",
    "from tsai.export import get_nb_name\n",
    "nb_name = get_nb_name()\n",
    "create_scripts(nb_name);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
