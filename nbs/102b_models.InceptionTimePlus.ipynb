{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.InceptionTimePlus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionTimePlus\n",
    "\n",
    "> This is an unofficial PyTorch implementation of InceptionTime (Fawaz, 2019) created by Ignacio Oguiza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "* Fawaz, H. I., Lucas, B., Forestier, G., Pelletier, C., Schmidt, D. F., Weber, J., ... & Petitjean, F. (2020). [Inceptiontime: Finding alexnet for time series classification. Data Mining and Knowledge Discovery, 34(6), 1936-1962.](https://arxiv.org/pdf/1909.04939)\n",
    "* Official InceptionTime tensorflow implementation: https://github.com/hfawaz/InceptionTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *\n",
    "from tsai.utils import *\n",
    "from tsai.models.layers import *\n",
    "from tsai.models.utils import *\n",
    "torch.set_num_threads(cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# This is an unofficial PyTorch implementation by Ignacio Oguiza - oguiza@gmail.com modified from:\n",
    "\n",
    "# Fawaz, H. I., Lucas, B., Forestier, G., Pelletier, C., Schmidt, D. F., Weber, J., ... & Petitjean, F. (2019). \n",
    "# InceptionTime: Finding AlexNet for Time Series Classification. arXiv preprint arXiv:1909.04939.\n",
    "# Official InceptionTime tensorflow implementation: https://github.com/hfawaz/InceptionTime\n",
    "\n",
    "    \n",
    "class InceptionModulePlus(Module):\n",
    "    def __init__(self, ni, nf, ks=40, bottleneck=True, padding='same', coord=False, separable=False, dilation=1, stride=1, conv_dropout=0., sa=False, se=None,\n",
    "                 norm='Batch', zero_norm=False, bn_1st=True, act=nn.ReLU, act_kwargs={}):\n",
    "        if isinstance(ks, Integral): ks = [ks // (2**i) for i in range(3)]\n",
    "        ks = [ksi if ksi % 2 != 0 else ksi - 1 for ksi in ks]  # ensure odd ks for padding='same'\n",
    "        bottleneck = False if ni == nf else bottleneck\n",
    "        self.bottleneck = Conv(ni, nf, 1, coord=coord, bias=False) if bottleneck else noop # \n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(len(ks)): self.convs.append(Conv(nf if bottleneck else ni, nf, ks[i], padding=padding, coord=coord, separable=separable,\n",
    "                                                         dilation=dilation**i, stride=stride, bias=False))\n",
    "        self.mp_conv = nn.Sequential(*[nn.MaxPool1d(3, stride=1, padding=1), Conv(ni, nf, 1, coord=coord, bias=False)])\n",
    "        self.concat = Concat()\n",
    "        self.norm = Norm(nf * 4, norm=norm, zero_norm=zero_norm)\n",
    "        self.conv_dropout = nn.Dropout(conv_dropout) if conv_dropout else noop\n",
    "        self.sa = SimpleSelfAttention(nf * 4) if sa else noop\n",
    "        self.act = act(**act_kwargs) if act else noop\n",
    "        self.se = nn.Sequential(SqueezeExciteBlock(nf * 4, reduction=se), BN1d(nf * 4)) if se else noop\n",
    "        \n",
    "        self._init_cnn(self)\n",
    "    \n",
    "    def _init_cnn(self, m):\n",
    "        if getattr(self, 'bias', None) is not None: nn.init.constant_(self.bias, 0)\n",
    "        if isinstance(self, (nn.Conv1d,nn.Conv2d,nn.Conv3d,nn.Linear)): nn.init.kaiming_normal_(self.weight)\n",
    "        for l in m.children(): self._init_cnn(l)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = x\n",
    "        x = self.bottleneck(x)\n",
    "        x = self.concat([l(x) for l in self.convs] + [self.mp_conv(input_tensor)])\n",
    "        x = self.norm(x)\n",
    "        x = self.conv_dropout(x)\n",
    "        x = self.sa(x)\n",
    "        x = self.act(x)\n",
    "        x = self.se(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "@delegates(InceptionModulePlus.__init__)\n",
    "class InceptionBlockPlus(Module):\n",
    "    def __init__(self, ni, nf, residual=True, depth=6, coord=False, norm='Batch', zero_norm=False, act=nn.ReLU, act_kwargs={}, sa=False, se=None, \n",
    "                 keep_prob=1., **kwargs):\n",
    "        self.residual, self.depth = residual, depth\n",
    "        self.inception, self.shortcut, self.act = nn.ModuleList(), nn.ModuleList(), nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            self.inception.append(InceptionModulePlus(ni if d == 0 else nf * 4, nf, coord=coord, norm=norm, \n",
    "                                                      zero_norm=zero_norm if d % 3 == 2 else False,\n",
    "                                                      act=act if d % 3 != 2 else None, act_kwargs=act_kwargs, \n",
    "                                                      sa=sa if d % 3 == 2 else False,\n",
    "                                                      se=se if d % 3 != 2 else None,\n",
    "                                                      **kwargs))\n",
    "            if self.residual and d % 3 == 2:\n",
    "                n_in, n_out = ni if d == 2 else nf * 4, nf * 4\n",
    "                self.shortcut.append(Norm(n_in, norm=norm) if n_in == n_out else ConvBlock(n_in, n_out, 1, coord=coord, bias=False, norm=norm, act=None))\n",
    "                self.act.append(act(**act_kwargs))\n",
    "        self.add = Add()\n",
    "        self.keep_prob = keep_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        for i in range(self.depth):\n",
    "            if self.training and self.keep_prob[i//3] < 1. and self.keep_prob[i//3] < random.random() and self.residual and i % 3 == 2: \n",
    "                res = x = self.act[i//3](self.shortcut[i//3](res))\n",
    "            else: \n",
    "                x = self.inception[i](x)\n",
    "                if self.residual and i % 3 == 2: res = x = self.act[i//3](self.add(x, self.shortcut[i//3](res)))\n",
    "        return x\n",
    "\n",
    "\n",
    "@delegates(InceptionModulePlus.__init__)\n",
    "class InceptionTimePlus(Module):\n",
    "    def __init__(self, c_in, c_out, seq_len=None, nf=32, nb_filters=None, concat_pool=False, fc_dropout=0., depth=6, stoch_depth=1., y_range=None, \n",
    "                 flatten=False, custom_head=None, **kwargs):\n",
    "        \n",
    "        nf = ifnone(nf, nb_filters) # for compatibility\n",
    "        self.fc_dropout, self.c_out, self.y_range = fc_dropout, c_out, y_range\n",
    "        self.c_out = c_out\n",
    "        \n",
    "        if stoch_depth is not 0: keep_prob = np.linspace(1, stoch_depth, depth // 3)\n",
    "        else: keep_prob = np.array([1] * depth // 3)\n",
    "        self.inceptionblock = InceptionBlockPlus(c_in, nf, depth=depth, keep_prob=keep_prob, **kwargs)\n",
    "        \n",
    "        self.head_nf = nf * 4\n",
    "        self.flatten = None\n",
    "        if flatten:  self.head_nf *= seq_len\n",
    "        self.flatten = Flatten() if flatten else None\n",
    "        if custom_head: self.head = custom_head(self.head_nf, c_out)\n",
    "        else: self.head = self.create_head(self.head_nf, c_out, concat_pool=concat_pool, fc_dropout=fc_dropout, y_range=y_range)\n",
    "        \n",
    "    def create_head(self, nf, c_out, concat_pool=False, fc_dropout=0., y_range=None, **kwargs):\n",
    "        if concat_pool: nf = nf * 2\n",
    "        layers = [GACP1d(1) if concat_pool else GAP1d(1)]\n",
    "        if fc_dropout: layers += [nn.Dropout(fc_dropout)]\n",
    "        layers += [nn.Linear(nf, c_out)]\n",
    "        if y_range: layers += [SigmoidRange(*y_range)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inceptionblock(x)\n",
    "        if self.flatten is not None: x = self.flatten(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class InCoordTime(InceptionTimePlus):\n",
    "    def __init__(self, *args, coord=True, zero_norm=True, **kwargs):\n",
    "        super().__init__(*args, coord=coord, zero_norm=zero_norm, **kwargs)\n",
    "\n",
    "\n",
    "class XCoordTime(InceptionTimePlus):\n",
    "    def __init__(self, *args, coord=True, separable=True, zero_norm=True, **kwargs):\n",
    "        super().__init__(*args, coord=coord, separable=separable, zero_norm=zero_norm, **kwargs)\n",
    "        \n",
    "InceptionTimePlus17x17 = partial(InceptionTimePlus, nf=17, depth=3)\n",
    "setattr(InceptionTimePlus17x17, '__name__', 'InceptionTimePlus17x17')\n",
    "InceptionTimePlus32x32 = InceptionTimePlus\n",
    "InceptionTimePlus47x47 = partial(InceptionTimePlus, nf=47, depth=9)\n",
    "setattr(InceptionTimePlus47x47, '__name__', 'InceptionTimePlus47x47')\n",
    "InceptionTimePlus62x62 = partial(InceptionTimePlus, nf=62, depth=9)\n",
    "setattr(InceptionTimePlus62x62, '__name__', 'InceptionTimePlus62x62')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(InceptionTimePlus.__init__)\n",
    "class MultiInceptionTimePlus(Module):\n",
    "    _arch = InceptionTimePlus\n",
    "    def __init__(self, feat_mask, c_out, seq_len=None, **kwargs):\n",
    "        r\"\"\"\n",
    "        MultiInceptionTimePlus is a class that allows you to create a model with multiple branches of InceptionTimePlus.\n",
    "        \n",
    "        Args:\n",
    "            - feat_mask: list with number of features that will be passed to each body.\n",
    "        \"\"\"\n",
    "        self.feat_mask = [feat_mask] if isinstance(feat_mask, int) else feat_mask \n",
    "        self.c_out = c_out\n",
    "        \n",
    "        # Body\n",
    "        self.branches = nn.ModuleList()\n",
    "        self.head_nf = 0\n",
    "        for feat in self.feat_mask:\n",
    "            m = create_model(self._arch, c_in=feat, c_out=c_out, seq_len=seq_len, **kwargs)\n",
    "            self.head_nf += m.head_nf\n",
    "            m.head = Noop\n",
    "            self.branches.append(m)\n",
    "        \n",
    "        # Head\n",
    "        self.head = self._arch.create_head(self, self.head_nf, c_out, **kwargs)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.split(x, self.feat_mask, dim=1)\n",
    "        for i, branch in enumerate(self.branches):\n",
    "            out = branch(x[i]) if i == 0 else torch.cat([out, branch(x[i])], dim=1)\n",
    "        return self.head(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "n_vars = 3\n",
    "seq_len = 12\n",
    "c_out = 2\n",
    "xb = torch.rand(bs, n_vars, seq_len)\n",
    "\n",
    "test_eq(InceptionTimePlus(n_vars,c_out)(xb).shape, [bs, c_out])\n",
    "test_eq(InceptionTimePlus(n_vars,c_out,concat_pool=True)(xb).shape, [bs, c_out])\n",
    "test_eq(InceptionTimePlus(n_vars,c_out, bottleneck=False)(xb).shape, [bs, c_out])\n",
    "test_eq(InceptionTimePlus(n_vars,c_out, residual=False)(xb).shape, [bs, c_out])\n",
    "test_eq(InceptionTimePlus(n_vars,c_out, conv_dropout=.5)(xb).shape, [bs, c_out])\n",
    "test_eq(InceptionTimePlus(n_vars,c_out, coord=True, separable=True, \n",
    "                          norm='Instance', zero_norm=True, bn_1st=False, fc_dropout=.5, sa=True, se=True, act=nn.PReLU, act_kwargs={})(xb).shape, [bs, c_out])\n",
    "test_eq(InceptionTimePlus(n_vars,c_out, coord=True, separable=True,\n",
    "                          norm='Instance', zero_norm=True, bn_1st=False, act=nn.PReLU, act_kwargs={})(xb).shape, [bs, c_out])\n",
    "test_eq(total_params(InceptionTimePlus(3, 2))[0], 455490)\n",
    "test_eq(total_params(InceptionTimePlus(6, 2, **{'coord': True, 'separable': True, 'zero_norm': True}))[0], 77204)\n",
    "test_eq(total_params(InceptionTimePlus(3, 2, ks=40))[0], total_params(InceptionTimePlus(3, 2, ks=[9, 19, 39]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InceptionTimePlus(n_vars, c_out, seq_len=seq_len, zero_norm=True, flatten=True, custom_head=create_mlp_head)(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(check_bias(InceptionTimePlus(2,3, zero_norm=True), is_conv)[0].sum(), 0)\n",
    "test_eq(check_weight(InceptionTimePlus(2,3, zero_norm=True), is_bn)[0].sum(), 6)\n",
    "test_eq(check_weight(InceptionTimePlus(2,3), is_bn)[0], np.array([1., 1., 1., 1., 1., 1., 1., 1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(count_parameters(MultiInceptionTimePlus([1,1,1], c_out)) > count_parameters(MultiInceptionTimePlus(3, c_out)), True)\n",
    "test_eq(MultiInceptionTimePlus([1,1,1], c_out)(xb).shape, MultiInceptionTimePlus(3, c_out)(xb).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10): InceptionTimePlus(n_vars,c_out,stoch_depth=0.8,depth=9,zero_norm=True)(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionTimePlus(\n",
       "  (inceptionblock): InceptionBlockPlus(\n",
       "    (inception): ModuleList(\n",
       "      (0): InceptionModulePlus(\n",
       "        (bottleneck): ConvBlock(\n",
       "          (0): AddCoords1d()\n",
       "          (1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        )\n",
       "        (convs): ModuleList(\n",
       "          (0): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(39,), stride=(1,), padding=(19,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(19,), stride=(1,), padding=(9,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (2): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(9,), stride=(1,), padding=(4,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (mp_conv): Sequential(\n",
       "          (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (concat): Concat(1)\n",
       "        (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "      )\n",
       "      (1): InceptionModulePlus(\n",
       "        (bottleneck): ConvBlock(\n",
       "          (0): AddCoords1d()\n",
       "          (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        )\n",
       "        (convs): ModuleList(\n",
       "          (0): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(39,), stride=(1,), padding=(19,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(19,), stride=(1,), padding=(9,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (2): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(9,), stride=(1,), padding=(4,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (mp_conv): Sequential(\n",
       "          (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (concat): Concat(1)\n",
       "        (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "      )\n",
       "      (2): InceptionModulePlus(\n",
       "        (bottleneck): ConvBlock(\n",
       "          (0): AddCoords1d()\n",
       "          (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        )\n",
       "        (convs): ModuleList(\n",
       "          (0): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(39,), stride=(1,), padding=(19,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(19,), stride=(1,), padding=(9,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (2): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(9,), stride=(1,), padding=(4,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (mp_conv): Sequential(\n",
       "          (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (concat): Concat(1)\n",
       "        (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InceptionModulePlus(\n",
       "        (bottleneck): ConvBlock(\n",
       "          (0): AddCoords1d()\n",
       "          (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        )\n",
       "        (convs): ModuleList(\n",
       "          (0): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(39,), stride=(1,), padding=(19,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(19,), stride=(1,), padding=(9,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (2): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(9,), stride=(1,), padding=(4,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (mp_conv): Sequential(\n",
       "          (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (concat): Concat(1)\n",
       "        (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "      )\n",
       "      (4): InceptionModulePlus(\n",
       "        (bottleneck): ConvBlock(\n",
       "          (0): AddCoords1d()\n",
       "          (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        )\n",
       "        (convs): ModuleList(\n",
       "          (0): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(39,), stride=(1,), padding=(19,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(19,), stride=(1,), padding=(9,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (2): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(9,), stride=(1,), padding=(4,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (mp_conv): Sequential(\n",
       "          (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (concat): Concat(1)\n",
       "        (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "      )\n",
       "      (5): InceptionModulePlus(\n",
       "        (bottleneck): ConvBlock(\n",
       "          (0): AddCoords1d()\n",
       "          (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        )\n",
       "        (convs): ModuleList(\n",
       "          (0): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(39,), stride=(1,), padding=(19,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(19,), stride=(1,), padding=(9,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (2): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): SeparableConv1d(\n",
       "              (depthwise_conv): Conv1d(33, 33, kernel_size=(9,), stride=(1,), padding=(4,), groups=33, bias=False)\n",
       "              (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (mp_conv): Sequential(\n",
       "          (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): ConvBlock(\n",
       "            (0): AddCoords1d()\n",
       "            (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (concat): Concat(1)\n",
       "        (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (shortcut): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (0): AddCoords1d()\n",
       "        (1): Conv1d(3, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act): ModuleList(\n",
       "      (0): ReLU()\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (add): Add\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): GAP1d(\n",
       "      (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "      (flatten): Flatten(full=False)\n",
       "    )\n",
       "    (1): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = InceptionTimePlus(2,3,**{'coord': True, 'separable': True, 'zero_norm': True})\n",
    "test_eq(check_weight(net, is_bn)[0], np.array([1., 1., 0., 1., 1., 0., 1., 1.]))\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AdaptiveAvgPool1d(output_size=1)\n",
       "  (1): Flatten(full=False)\n",
       "  (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Linear(in_features=128, out_features=512, bias=False)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): Linear(in_features=512, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 16\n",
    "n_vars = 3\n",
    "seq_len = 12\n",
    "c_out = 2\n",
    "xb = torch.rand(bs, n_vars, seq_len)\n",
    "net = MultiInceptionTimePlus(n_vars, c_out)\n",
    "change_model_head(net, create_pool_plus_head, concat_pool=False)\n",
    "print(net(xb).shape)\n",
    "net.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 000_utils.ipynb.\n",
      "Converted 000b_data.validation.ipynb.\n",
      "Converted 001_data.external.ipynb.\n",
      "Converted 002_data.core.ipynb.\n",
      "Converted 003_data.preprocessing.ipynb.\n",
      "Converted 003b_data.transforms.ipynb.\n",
      "Converted 003c_data.image.ipynb.\n",
      "Converted 005_data.tabular.ipynb.\n",
      "Converted 006_data.mixed.ipynb.\n",
      "Converted 007_metrics.ipynb.\n",
      "Converted 008_learner.ipynb.\n",
      "Converted 009_optimizer.ipynb.\n",
      "Converted 010_callback.core.ipynb.\n",
      "Converted 011_callback.semi_supervised.ipynb.\n",
      "Converted 100_models.utils.ipynb.\n",
      "Converted 100b_models.layers.ipynb.\n",
      "Converted 101_models.ResNet.ipynb.\n",
      "Converted 101b_models.ResNetPlus.ipynb.\n",
      "Converted 102_models.InceptionTime.ipynb.\n",
      "Converted 102b_models.InceptionTimePlus.ipynb.\n",
      "Converted 103_models.MLP.ipynb.\n",
      "Converted 103b_models.FCN.ipynb.\n",
      "Converted 103c_models.FCNPlus.ipynb.\n",
      "Converted 104_models.ResCNN.ipynb.\n",
      "Converted 105_models.RNN.ipynb.\n",
      "Converted 105_models.RNNPlus.ipynb.\n",
      "Converted 106_models.XceptionTime.ipynb.\n",
      "Converted 106b_models.XceptionTimePlus.ipynb.\n",
      "Converted 107_models.RNN_FCN.ipynb.\n",
      "Converted 107b_models.RNN_FCNPlus.ipynb.\n",
      "Converted 108_models.TransformerModel.ipynb.\n",
      "Converted 108b_models.TST.ipynb.\n",
      "Converted 108c_models.TSTPlus.ipynb.\n",
      "Converted 109_models.OmniScaleCNN.ipynb.\n",
      "Converted 110_models.mWDN.ipynb.\n",
      "Converted 111_models.ROCKET.ipynb.\n",
      "Converted 112_models.XResNet1d.ipynb.\n",
      "Converted 112b_models.XResNet1dPlus.ipynb.\n",
      "Converted 120_models.TabModel.ipynb.\n",
      "Converted 130_models.HybridDL.ipynb.\n",
      "Converted 200_trading.utils.ipynb.\n",
      "Converted 900_tutorials.ipynb.\n",
      "Converted index.ipynb.\n",
      "\n",
      "\n",
      "Checking folder: /Users/nacho/Documents/Machine_Learning/Jupyter_Notebooks/tsai/tsai\n",
      "Correct conversion! ðŸ˜ƒ\n",
      "Total time elapsed 85 s\n",
      "Monday 11/16/20 14:54:32 CET\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "out = create_scripts()\n",
    "beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
