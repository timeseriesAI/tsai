{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "\n",
    "> Helper functions used throughout the library not related to timeseries data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python         : 3.7.6\n",
      "tsai           : 0.2.3\n",
      "fastai         : 2.1.5\n",
      "fastcore       : 1.3.2\n",
      "torch          : 1.7.0\n",
      "scipy          : 1.5.2\n",
      "numpy          : 1.19.1\n",
      "pandas         : 1.1.3\n",
      "matplotlib     : 3.3.2\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import tsai\n",
    "a = !python  -V\n",
    "p = a[0].split(' ')\n",
    "print(f'python         : {p[1]}')\n",
    "print('tsai           :', tsai.__version__)\n",
    "print('fastai         :', fastai.__version__)\n",
    "print('fastcore       :', fastcore.__version__)\n",
    "print('torch          :', torch.__version__)\n",
    "print('scipy          :', sp.__version__)\n",
    "print('numpy          :', np.__version__)\n",
    "print('pandas         :', pd.__version__)\n",
    "print('matplotlib     :', matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import inspect\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def totensor(o):\n",
    "    if isinstance(o, torch.Tensor): return o\n",
    "    elif isinstance(o, np.ndarray):  return torch.from_numpy(o)\n",
    "    elif isinstance(o, (list, L)): return torch.tensor(o)\n",
    "    assert False, f\"Can't convert {type(o)} to torch.Tensor\"\n",
    "\n",
    "\n",
    "def toarray(o):\n",
    "    if isinstance(o, np.ndarray): return o\n",
    "    elif isinstance(o, torch.Tensor): return o.cpu().numpy()\n",
    "    elif isinstance(o, (list, L)): return np.array(o)\n",
    "    assert False, f\"Can't convert {type(o)} to np.array\"\n",
    "    \n",
    "    \n",
    "def toL(o):\n",
    "    if isinstance(o, L): return o\n",
    "    elif isinstance(o, list): return L(o)\n",
    "    elif isinstance(o, (np.ndarray, torch.Tensor)): return L(o.tolist())\n",
    "    assert False, f'passed object needs to be of type L, list, np.ndarray or torch.Tensor but is {type(o)}'\n",
    "\n",
    "\n",
    "def to3dtensor(o):\n",
    "    o = totensor(o)\n",
    "    if o.ndim == 3: return o\n",
    "    elif o.ndim == 1: return o[None, None]\n",
    "    elif o.ndim == 2: return o[:, None]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to2dtensor(o):\n",
    "    o = totensor(o)\n",
    "    if o.ndim == 2: return o\n",
    "    elif o.ndim == 1: return o[None]\n",
    "    elif o.ndim == 3: return o[0]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to1dtensor(o):\n",
    "    o = totensor(o)\n",
    "    if o.ndim == 1: return o\n",
    "    elif o.ndim == 3: return o[0,0]\n",
    "    if o.ndim == 2: return o[0]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to3darray(o):\n",
    "    o = toarray(o)\n",
    "    if o.ndim == 3: return o\n",
    "    elif o.ndim == 1: return o[None, None]\n",
    "    elif o.ndim == 2: return o[:, None]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to2darray(o):\n",
    "    o = toarray(o)\n",
    "    if o.ndim == 2: return o\n",
    "    elif o.ndim == 1: return o[None]\n",
    "    elif o.ndim == 3: return o[0]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to1darray(o):\n",
    "    o = toarray(o)\n",
    "    if o.ndim == 1: return o\n",
    "    elif o.ndim == 3: o = o[0,0]\n",
    "    elif o.ndim == 2: o = o[0]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "    \n",
    "    \n",
    "def to3d(o):\n",
    "    if o.ndim == 3: return o\n",
    "    if isinstance(o, np.ndarray): return to3darray(o)\n",
    "    if isinstance(o, torch.Tensor): return to3dtensor(o)\n",
    "    \n",
    "    \n",
    "def to2d(o):\n",
    "    if o.ndim == 2: return o\n",
    "    if isinstance(o, np.ndarray): return to2darray(o)\n",
    "    if isinstance(o, torch.Tensor): return to2dtensor(o)\n",
    "    \n",
    "    \n",
    "def to1d(o):\n",
    "    if o.ndim == 1: return o\n",
    "    if isinstance(o, np.ndarray): return to1darray(o)\n",
    "    if isinstance(o, torch.Tensor): return to1dtensor(o)\n",
    "    \n",
    "    \n",
    "def to2dPlus(o):\n",
    "    if o.ndim >= 2: return o\n",
    "    if isinstance(o, np.ndarray): return to2darray(o)\n",
    "    elif isinstance(o, torch.Tensor): return to2dtensor(o)\n",
    "    \n",
    "    \n",
    "def to3dPlus(o):\n",
    "    if o.ndim >= 3: return o\n",
    "    if isinstance(o, np.ndarray): return to3darray(o)\n",
    "    elif isinstance(o, torch.Tensor): return to3dtensor(o)\n",
    "    \n",
    "    \n",
    "def to2dPlusTensor(o):\n",
    "    return to2dPlus(totensor(o))\n",
    "\n",
    "\n",
    "def to2dPlusArray(o):\n",
    "    return to2dPlus(toarray(o))\n",
    "\n",
    "\n",
    "def to3dPlusTensor(o):\n",
    "    return to3dPlus(totensor(o))\n",
    "\n",
    "\n",
    "def to3dPlusArray(o):\n",
    "    return to3dPlus(toarray(o))\n",
    "\n",
    "\n",
    "def todtype(dtype):\n",
    "    def _to_type(o, dtype=dtype):\n",
    "        if o.dtype == dtype: return o\n",
    "        elif isinstance(o, torch.Tensor): o = o.to(dtype=dtype)\n",
    "        elif isinstance(o, np.ndarray): o = o.astype(dtype)\n",
    "        return o\n",
    "    return _to_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(100).astype(np.float32)\n",
    "b = torch.from_numpy(a).float()\n",
    "test_eq(totensor(a), b)\n",
    "test_eq(a, toarray(b))\n",
    "test_eq(to3dtensor(a).ndim, 3)\n",
    "test_eq(to2dtensor(a).ndim, 2)\n",
    "test_eq(to1dtensor(a).ndim, 1)\n",
    "test_eq(to3darray(b).ndim, 3)\n",
    "test_eq(to2darray(b).ndim, 2)\n",
    "test_eq(to1darray(b).ndim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bytes2size(size_bytes):\n",
    "    if size_bytes == 0: return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "def bytes2GB(byts):\n",
    "    return round(byts / math.pow(1024, 3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def delete_all_in_dir(tgt_dir, exception=None):\n",
    "    if exception is not None and len(L(exception)) > 1: exception = tuple(exception)\n",
    "    for file in os.listdir(tgt_dir):\n",
    "        if exception is not None and file.endswith(exception): continue\n",
    "        file_path = os.path.join(tgt_dir, file)\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path): os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path): shutil.rmtree(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def reverse_dict(dictionary): \n",
    "    return {v: k for k, v in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_tuple(o): return isinstance(o, tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def itemify(*o, tup_id=None): \n",
    "    o = [o_ for o_ in L(*o) if o_ is not None]\n",
    "    items = L(o).zip()\n",
    "    if tup_id is not None: return L([item[tup_id] for item in items])\n",
    "    else: return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 4), (2, 5), (3, 6)]\n",
      "[(1,), (2,), (3,)]\n",
      "[(1, 4), (2, 5), (3, 6)]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "print(itemify(a, b))\n",
    "test_eq(len(itemify(a, b)), len(a))\n",
    "a = [1, 2, 3]\n",
    "b = None\n",
    "print(itemify(a, b))\n",
    "test_eq(len(itemify(a, b)), len(a))\n",
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "c = None\n",
    "print(itemify(a, b, c))\n",
    "test_eq(len(itemify(a, b, c)), len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def isnone(o):\n",
    "    return o is None\n",
    "\n",
    "def exists(o): return o is not None\n",
    "\n",
    "def ifelse(a, b, c):\n",
    "    \"`b` if `a` is True else `c`\"\n",
    "    return b if a else c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(3)\n",
    "test_eq(isnone(a), False)\n",
    "test_eq(exists(a), True)\n",
    "b = None\n",
    "test_eq(isnone(b), True)\n",
    "test_eq(exists(b), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_not_close(a, b, eps=1e-5):\n",
    "    \"Is `a` within `eps` of `b`\"\n",
    "    if hasattr(a, '__array__') or hasattr(b, '__array__'):\n",
    "        return (abs(a - b) > eps).all()\n",
    "    if isinstance(a, (Iterable, Generator)) or isinstance(b, (Iterable, Generator)):\n",
    "        return is_not_close(np.array(a), np.array(b), eps=eps)\n",
    "    return abs(a - b) > eps\n",
    "\n",
    "\n",
    "def test_not_close(a, b, eps=1e-5):\n",
    "    \"`test` that `a` is within `eps` of `b`\"\n",
    "    test(a, b, partial(is_not_close, eps=eps), 'not_close')\n",
    "\n",
    "\n",
    "def test_type(a, b):\n",
    "    return test_eq(type(a), type(b))\n",
    "\n",
    "\n",
    "def test_ok(f, *args, **kwargs):\n",
    "    try: \n",
    "        f(*args, **kwargs)\n",
    "        e = 0\n",
    "    except: \n",
    "        e = 1\n",
    "        pass\n",
    "    test_eq(e, 0)\n",
    "    \n",
    "def test_not_ok(f, *args, **kwargs):\n",
    "    try: \n",
    "        f(*args, **kwargs)\n",
    "        e = 0\n",
    "    except: \n",
    "        e = 1\n",
    "        pass\n",
    "    test_eq(e, 1)\n",
    "    \n",
    "def test_error(error, f, *args, **kwargs):\n",
    "    try: f(*args, **kwargs)\n",
    "    except Exception as e: \n",
    "        test_eq(str(e), error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def assert_fn(*args, **kwargs): assert False, 'assertion test'\n",
    "test_error('assertion test', assert_fn, 35, a=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def test_gt(a,b):\n",
    "    \"`test` that `a>b`\"\n",
    "    test(a,b,gt,'>')\n",
    "\n",
    "def test_ge(a,b):\n",
    "    \"`test` that `a>=b`\"\n",
    "    test(a,b,ge,'>')\n",
    "    \n",
    "def test_lt(a,b):\n",
    "    \"`test` that `a>b`\"\n",
    "    test(a,b,lt,'<')\n",
    "\n",
    "def test_le(a,b):\n",
    "    \"`test` that `a>b`\"\n",
    "    test(a,b,le,'<=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ok(test_gt, 5, 4)\n",
    "test_not_ok(test_gt, 4, 4)\n",
    "test_ok(test_ge, 4, 4)\n",
    "test_not_ok(test_ge, 3, 4)\n",
    "\n",
    "test_ok(test_lt, 3, 4)\n",
    "test_not_ok(test_lt, 4, 4)\n",
    "test_ok(test_le, 4, 4)\n",
    "test_not_ok(test_le, 5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def stack(o, axis=0, retain=True):\n",
    "    if isinstance(o[0], torch.Tensor): \n",
    "        return retain_type(torch.stack(tuple(o), dim=axis),  o[0]) if retain else torch.stack(tuple(o), dim=axis)\n",
    "    else: \n",
    "        return retain_type(np.stack(o, axis), o[0]) if retain else np.stack(o, axis)\n",
    "    \n",
    "def stack_pad(l):\n",
    "    def resize(row, size):\n",
    "        new = np.array(row)\n",
    "        new.resize(size)\n",
    "        return new\n",
    "    row_length = max(l, key=len).__len__()\n",
    "    mat = np.array([resize(row, row_length) for row in l])\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[0,1,2], [4,5,6,7]]\n",
    "test_eq(stack_pad(a).shape, (2, 4))\n",
    "test_eq(type(stack_pad(a)), np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(2, 3, 4)\n",
    "t = torch.from_numpy(a)\n",
    "test_eq_type(stack(itemify(a, tup_id=0)), a)\n",
    "test_eq_type(stack(itemify(t, tup_id=0)), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def random_shuffle(o, random_state=None):\n",
    "    res = sklearn.utils.shuffle(o, random_state=random_state)\n",
    "    if isinstance(o, L): return L(list(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "test_eq_type(random_shuffle(a, 1), np.array([2, 9, 6, 4, 0, 3, 1, 7, 8, 5]))\n",
    "t = torch.arange(10)\n",
    "test_eq_type(random_shuffle(t, 1), tensor([2, 9, 6, 4, 0, 3, 1, 7, 8, 5]))\n",
    "l = list(a)\n",
    "test_eq(random_shuffle(l, 1), [2, 9, 6, 4, 0, 3, 1, 7, 8, 5])\n",
    "l2 = L(l)\n",
    "test_eq_type(random_shuffle(l2, 1), L([2, 9, 6, 4, 0, 3, 1, 7, 8, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cat2int(o):\n",
    "    cat = Categorize()\n",
    "    cat.setup(o)\n",
    "    return stack(TfmdLists(o, cat)[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(['b', 'a', 'a', 'b', 'a', 'b', 'a'])\n",
    "test_eq_type(cat2int(a), TensorCategory([1, 0, 0, 1, 0, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase([1, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorBase([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cycle_dl(dl): \n",
    "    for _ in dl: _\n",
    "        \n",
    "def cycle_dl_to_device(dl):\n",
    "    for bs in dl: [b.to(default_device()) for b in bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cache_memmap(o, slice_len=1000, verbose=False):\n",
    "    start = 0\n",
    "    slice_len = 1000\n",
    "    for i in range(len(o) // 1000 + 1): \n",
    "        o[start:start + slice_len]\n",
    "        start += slice_len\n",
    "        if verbose and i % 10 == 0: print(i)\n",
    "    \n",
    "memmap2cache =  cache_memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_func_defaults(f): \n",
    "    fa = inspect.getfullargspec(f)\n",
    "    if fa.defaults is None: return dict(zip(fa.args, [''] * (len(fa.args))))\n",
    "    else: return dict(zip(fa.args, [''] * (len(fa.args) - len(fa.defaults)) + list(fa.defaults)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_idx_from_df_col_vals(df, col, val_list):\n",
    "    return [df[df[col] == val].index[0] for val in val_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_sublist_idxs(aList, bList):\n",
    "    \"Get idxs that when applied to aList will return bList. aList must contain all values in bList\"\n",
    "    sorted_aList = aList[np.argsort(aList)]\n",
    "    return np.argsort(aList)[np.searchsorted(sorted_aList, bList)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([3, 5, 7, 1, 9, 8, 6, 2])\n",
    "y = np.array([6, 1, 5, 7])\n",
    "idx = get_sublist_idxs(x, y)\n",
    "test_eq(x[idx], y)\n",
    "x = np.array([3, 5, 7, 1, 9, 8, 6, 6, 2])\n",
    "y = np.array([6, 1, 5, 7, 5])\n",
    "idx = get_sublist_idxs(x, y)\n",
    "test_eq(x[idx], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def display_pd_df(df, max_rows:Union[bool, int]=False, max_columns:Union[bool, int]=False):\n",
    "    if max_rows:\n",
    "        old_max_rows = pd.get_option('display.max_rows')\n",
    "        if max_rows is not True and isinstance(max_rows, Integral): pd.set_option('display.max_rows', max_rows)\n",
    "        else: pd.set_option('display.max_rows', df.shape[0])\n",
    "    if max_columns:\n",
    "        old_max_columns = pd.get_option('display.max_columns')\n",
    "        if max_columns is not True and isinstance(max_columns, Integral): pd.set_option('display.max_columns', max_columns)\n",
    "        else: pd.set_option('display.max_columns', df.shape[1])\n",
    "    display(df)\n",
    "    if max_rows: pd.set_option('display.max_rows', old_max_rows)\n",
    "    if max_columns: pd.set_option('display.max_columns', old_max_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.558880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.413416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0   ...        24\n",
       "0   0.558880  ...  0.588927\n",
       "..       ...  ...       ...\n",
       "69  0.413416  ...  0.660007\n",
       "\n",
       "[70 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "old_max_rows, old_max_columns = pd.get_option('display.max_rows'), pd.get_option('display.max_columns')\n",
    "df = pd.DataFrame(np.random.rand(70, 25))\n",
    "display_pd_df(df, max_rows=2, max_columns=3)\n",
    "test_eq(old_max_rows, pd.get_option('display.max_rows'))\n",
    "test_eq(old_max_columns, pd.get_option('display.max_columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ttest(data1, data2, equal_var=False):\n",
    "    \"Calculates t-statistic and p-value based on 2 sample distributions\"\n",
    "    t_stat, p_value = scipy.stats.ttest_ind(data1, data2, equal_var=equal_var)\n",
    "    return t_stat, np.sign(t_stat) * p_value\n",
    "\n",
    "def tscore(o): \n",
    "    if o.std() == 0: return 0\n",
    "    else: return np.sqrt(len(o)) * o.mean() / o.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3.424827897643452, 0.0007965968632810326)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.normal(0.5, 1, 100)\n",
    "b = np.random.normal(0.15, .5, 50)\n",
    "plt.hist(a, 50)\n",
    "plt.hist(b, 50)\n",
    "plt.show()\n",
    "ttest(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.77768699623661, tensor(5.2084))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.normal(0.5, 1, 100)\n",
    "t = torch.normal(0.5, 1, (100, ))\n",
    "tscore(a), tscore(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ttest_tensor(a, b):\n",
    "    \"differentiable pytorch function equivalent to scipy.stats.ttest_ind with equal_var=False\"\n",
    "    # calculate standard errors\n",
    "    se1, se2 = torch.std(a)/np.sqrt(len(a)), torch.std(b)/np.sqrt(len(b))\n",
    "    # standard error on the difference between the samples\n",
    "    sed = torch.sqrt(se1**2.0 + se2**2.0)\n",
    "    # calculate the t statistic\n",
    "    t_stat = (torch.mean(a) - torch.mean(b)) / sed\n",
    "    return t_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5467, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(100).requires_grad_(True) + .1\n",
    "b = torch.rand(100).requires_grad_(True)\n",
    "ttest_tensor(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1712444951542046, 0.1489108910891089)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#export\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def pcc(a, b):\n",
    "    return pearsonr(a, b)[0]\n",
    "\n",
    "def scc(a, b):\n",
    "    return spearmanr(a, b)[0]\n",
    "\n",
    "a = np.random.normal(0.5, 1, 100)\n",
    "b = np.random.normal(0.15, .5, 100)\n",
    "pcc(a, b), scc(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_fn(fn, verbose=False):\n",
    "    \"Removes a file (fn) if exists\"\n",
    "    try: \n",
    "        os.remove(fn)\n",
    "        pv(f'{fn} file removed', verbose)\n",
    "    except OSError: \n",
    "        pv(f'{fn} does not exist', verbose)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/remove_fn_test.npy file removed\n",
      "data/remove_fn_test.npy does not exist\n"
     ]
    }
   ],
   "source": [
    "fn = 'data/remove_fn_test.npy'\n",
    "a = np.zeros(1)\n",
    "np.save(fn, a)\n",
    "remove_fn(fn, True)\n",
    "remove_fn(fn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def npsave(array_fn, array, verbose=True):\n",
    "    remove_fn(array_fn, verbose)\n",
    "    pv(f'saving {array_fn}...', verbose)\n",
    "    np.save(array_fn, array)\n",
    "    pv(f'...{array_fn} saved', verbose)\n",
    "    \n",
    "np_save = npsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'data/remove_fn_test.npy'\n",
    "a = np.zeros(1)\n",
    "npsave(fn, a)\n",
    "del a\n",
    "np.load(fn, mmap_mode='r+')\n",
    "remove_fn(fn, True)\n",
    "remove_fn(fn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def permute_2D(array, axis=None):\n",
    "    \"Permute rows or columns in an array. This can be used, for example, in feature permutation\"\n",
    "    if axis == 0: return array[np.random.randn(*array.shape).argsort(axis=0), np.arange(array.shape[-1])[None, :]] \n",
    "    elif axis == 1 or axis == -1: return array[np.arange(len(array))[:,None], np.random.randn(*array.shape).argsort(axis=1)] \n",
    "    return array[np.random.randn(*array.shape).argsort(axis=0), np.random.randn(*array.shape).argsort(axis=1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.arange(100 * 50).reshape(100, 50) \n",
    "test_eq(permute_2D(s, axis=0).mean(0), s.mean(0))\n",
    "test_ne(permute_2D(s, axis=0), s)\n",
    "test_eq(permute_2D(s, axis=1).mean(1), s.mean(1))\n",
    "test_ne(permute_2D(s, axis=1), s)\n",
    "test_ne(permute_2D(s), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def random_normal():\n",
    "    \"Returns a number between -1 and 1 with a normal distribution\"\n",
    "    while True:\n",
    "        o = np.random.normal(loc=0., scale=1/3)\n",
    "        if abs(o) <= 1: break\n",
    "    return o\n",
    "\n",
    "def random_half_normal():\n",
    "    \"Returns a number between 0 and 1 with a half-normal distribution\"\n",
    "    while True:\n",
    "        o = abs(np.random.normal(loc=0., scale=1/3))\n",
    "        if o <= 1: break\n",
    "    return o\n",
    "\n",
    "def random_normal_tensor(shape=1, device=None):\n",
    "    \"Returns a tensor of a predefined shape between -1 and 1 with a normal distribution\"\n",
    "    return torch.empty(shape, device=device).normal_(mean=0, std=1/3).clamp_(-1, 1)\n",
    "\n",
    "def random_half_normal_tensor(shape=1, device=None):\n",
    "    \"Returns a tensor of a predefined shape between 0 and 1 with a half-normal distribution\"\n",
    "    return abs(torch.empty(shape, device=device).normal_(mean=0, std=1/3)).clamp_(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def clip_outliers(o):\n",
    "    Q1, Q3 = np.percentile(o, [25, 75])\n",
    "    IQR = Q3 - Q1\n",
    "    if isinstance(o, (np.ndarray, pd.core.series.Series)):\n",
    "        return np.clip(o, Q1 - 1.5 * IQR, Q3 + 1.5 * IQR)\n",
    "    elif isinstance(o, torch.Tensor):\n",
    "        return torch.clamp(o, Q1 - 1.5 * IQR, Q3 + 1.5 * IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "\n",
    "def default_dpi():\n",
    "    DPI = plt.gcf().get_dpi()\n",
    "    plt.close()\n",
    "    return int(DPI)\n",
    "\n",
    "def get_plot_fig(size=None, dpi=default_dpi()):\n",
    "    fig = plt.figure(figsize=(size / dpi, size / dpi), dpi=dpi, frameon=False) if size else plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    config = plt.gcf()\n",
    "    plt.close('all')\n",
    "    return config\n",
    "\n",
    "def fig2buf(fig):\n",
    "    canvas = FigureCanvasAgg(fig)\n",
    "    fig.canvas.draw()\n",
    "    return np.asarray(canvas.buffer_rgba())[..., :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_dpi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def plot_scatter(x, y, deg=1):\n",
    "    linreg = sp.stats.linregress(x, y)\n",
    "    plt.scatter(x, y, label=f'R2:{linreg.rvalue:.2f}', color='lime', edgecolor='black', alpha=.5)\n",
    "    plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, deg))(np.unique(x)), color='r')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(100)\n",
    "b = np.random.rand(100)**2\n",
    "plot_scatter(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import seaborn as sns\n",
    "def jointplot_scatter(x,y,**kwargs):\n",
    "    sns.jointplot(x, y, kind='scatter', **kwargs)\n",
    "    plt.show()\n",
    "    \n",
    "def jointplot_kde(x,y,**kwargs):\n",
    "    sns.jointplot(x, y, kind='kde', **kwargs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_idxs(o, aList): return array([o.tolist().index(v) for v in aList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = random_shuffle(np.arange(100, 200))\n",
    "b = np.random.choice(a, 10, False)\n",
    "idxs = get_idxs(a, b)\n",
    "test_eq(a[idxs], b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def apply_cmap(o, cmap):\n",
    "    o = toarray(o)\n",
    "    out = plt.get_cmap(cmap)(o)[..., :3]\n",
    "    out = tensor(out).squeeze(1)\n",
    "    return out.permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(16, 1, 40, 50)\n",
    "s = L(a.shape)\n",
    "s[1] = 3\n",
    "test_eq(L(apply_cmap(a, 'viridis').shape), s)\n",
    "\n",
    "s[0] = 1\n",
    "a = np.random.rand(1, 40, 50)\n",
    "test_eq(L(apply_cmap(a, 'viridis').shape), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def torch_tile(a, n_tile, dim=0):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)]))\n",
    "    return torch.index_select(a, dim, order_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(torch_tile(torch.arange(2), 3), tensor([0, 0, 0, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_tsfresh_dataset(ts):\n",
    "    r\"\"\"Prepares a time series (Tensor/ np.ndarray) to be used as a tsfresh dataset to allow feature extraction\"\"\"\n",
    "    if isinstance(ts, np.ndarray):\n",
    "        ids = np.repeat(np.arange(len(ts)), ts.shape[-1]).reshape(-1,1)\n",
    "        joint_ts =  ts.transpose(0,2,1).reshape(-1, ts.shape[1])\n",
    "        cols = ['id']+np.arange(ts.shape[1]).tolist()\n",
    "        return pd.DataFrame(np.concatenate([ids, joint_ts], axis=1), columns=cols)\n",
    "    elif isinstance(ts, torch.Tensor):\n",
    "        ids = torch_tile(torch.arange(len(ts)), ts.shape[-1]).reshape(-1,1)\n",
    "        joint_ts =  ts.transpose(1,2).reshape(-1, ts.shape[1])\n",
    "        cols = ['id']+np.arange(ts.shape[1]).tolist()\n",
    "        return pd.DataFrame(torch.cat([ids, joint_ts], dim=1).numpy(), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = torch.rand(16, 3, 20)\n",
    "a = to_tsfresh_dataset(ts)\n",
    "ts = ts.numpy()\n",
    "b = to_tsfresh_dataset(ts)\n",
    "test_eq(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def pcorr(a, b): \n",
    "    return scipy.stats.pearsonr(a, b)\n",
    "\n",
    "def scorr(a, b): \n",
    "    corr = scipy.stats.spearmanr(a, b)\n",
    "    return corr[0], corr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "out = create_scripts()\n",
    "beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
