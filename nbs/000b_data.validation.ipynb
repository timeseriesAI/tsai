{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data\n",
    "\n",
    "> Functions required to perform cross-validation and transform unique time series sequence into multiple samples ready to be used by a time series model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *\n",
    "from tsai.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def check_overlap(a, b):\n",
    "    a = toarray(a)\n",
    "    b = toarray(b)\n",
    "    overlap = np.isin(a, b)\n",
    "    if isinstance(overlap[0], (list, L, np.ndarray, torch.Tensor)):  overlap = overlap[0] \n",
    "    if not any(overlap): return False\n",
    "    else: return a[overlap]\n",
    "\n",
    "\n",
    "def leakage_finder(*splits, verbose=True):\n",
    "    '''You can pass splits as a tuple, or train, valid, ...'''\n",
    "    splits = L(*splits)\n",
    "    overlaps = 0\n",
    "    for i in range(len(splits)):\n",
    "        for j in range(i + 1, len(splits)):\n",
    "            overlap = check_overlap(splits[i], splits[j])\n",
    "            if overlap: \n",
    "                pv(f'overlap between splits [{i}, {j}] {overlap}', verbose)\n",
    "                overlaps += 1\n",
    "    assert overlaps == 0, 'Please, review your splits!'\n",
    "\n",
    "\n",
    "def balance_idx(o, shuffle=False, random_state=None, verbose=False):\n",
    "    if isinstance(o, list): o = L(o)\n",
    "    idx_ = np.arange(len(o)).reshape(-1, 1)\n",
    "    ros = RandomOverSampler(random_state=random_state)\n",
    "    resampled_idxs, _ = ros.fit_resample(idx_, np.asarray(o))\n",
    "    new_idx = L(resampled_idxs.reshape(-1,).tolist())\n",
    "    if shuffle: new_idx = random_shuffle(new_idx)\n",
    "    return new_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "b = np.arange(10, 20)\n",
    "test_eq(check_overlap(a, b), False)\n",
    "a = np.arange(10)\n",
    "b = np.arange(9, 20)\n",
    "test_eq(check_overlap(a, b), [9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = L(list(concat(np.zeros(5), np.ones(10)).astype(int)))\n",
    "balanced_idx = balance_idx(l)\n",
    "test_eq(np.mean(l[balanced_idx]), 0.5)\n",
    "test_eq(isinstance(balanced_idx, L), True)\n",
    "\n",
    "l = list(concat(np.zeros(5), np.ones(10)).astype(int))\n",
    "balanced_idx = balance_idx(l)\n",
    "test_eq(np.mean(L(l)[balanced_idx]), 0.5)\n",
    "test_eq(isinstance(balanced_idx, L), True)\n",
    "\n",
    "a = concat(np.zeros(5), np.ones(10)).astype(int)\n",
    "balanced_idx = balance_idx(a)\n",
    "test_eq(np.mean(a[balanced_idx]), 0.5)\n",
    "test_eq(isinstance(balanced_idx, L), True)\n",
    "\n",
    "t = concat(torch.zeros(5), torch.ones(10))\n",
    "balanced_idx = balance_idx(t, shuffle=True)\n",
    "test_eq(t[balanced_idx].mean(), 0.5)\n",
    "test_eq(isinstance(balanced_idx, L), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.arange(100_000), np.arange(100_000, 200_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_labels = True\n",
    "filter_pseudolabels = .5\n",
    "balanced_pseudolabels = True\n",
    "\n",
    "\n",
    "pseudolabels = torch.rand(1000, 3)\n",
    "pseudolabels = torch.softmax(pseudolabels, -1) if soft_labels else torch.argmax(pseudolabels, -1)\n",
    "hpl = torch.argmax(pseudolabels, -1) if soft_labels else pseudolabels\n",
    "\n",
    "if filter_pseudolabels and pseudolabels.ndim > 1: \n",
    "    error = 1 - pseudolabels.max(-1).values\n",
    "    filt_pl_idx = np.arange(len(error))[error < filter_pseudolabels]\n",
    "    filt_pl = pseudolabels[error < filter_pseudolabels]\n",
    "    assert len(filt_pl) > 0, 'no filtered pseudolabels'\n",
    "    filt_hpl = torch.argmax(filt_pl, -1)\n",
    "else: \n",
    "    filt_pl_idx = np.arange(len(pseudolabels))\n",
    "    filt_pl = filt_hpl = pseudolabels\n",
    "pl_split = filt_pl_idx[balance_idx(filt_hpl)] if balanced_pseudolabels else filt_pl_idx\n",
    "test_eq(hpl[pl_split].float().mean(), np.mean(np.unique(hpl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def TrainValidTestSplitter(n_splits:int=1, valid_size:Union[float, int]=0.2, test_size:Union[float, int]=0., train_only:bool=False,\n",
    "                           stratify:bool=True, balance:bool=False, shuffle:bool=True, random_state:Union[None, int]=None, verbose:bool=False, **kwargs):\n",
    "    \"Split `items` into random train, valid (and test optional) subsets.\"\n",
    "    \n",
    "    if not shuffle and stratify and not train_only: \n",
    "        pv('stratify set to False because shuffle=False. If you want to stratify set shuffle=True', verbose)\n",
    "        stratify = False\n",
    "        \n",
    "    def _inner(o, **kwargs):\n",
    "        if stratify:\n",
    "            n_unique, unique_counts = np.unique(o, return_counts=True)\n",
    "            if np.min(unique_counts) >= 2 and np.min(unique_counts) >= n_splits: stratify_ = stratify  \n",
    "            elif np.min(unique_counts) < n_splits: \n",
    "                stratify_ = False\n",
    "                pv(f'stratify set to False as n_splits={n_splits} cannot be greater than the min number of members in each class ({np.min(unique_counts)}).', \n",
    "                   verbose)\n",
    "            else:\n",
    "                stratify_ = False\n",
    "                pv('stratify set to False as the least populated class in o has only 1 member, which is too few.', verbose)\n",
    "        else: stratify_ = False\n",
    "        vs = 0 if train_only else 1. / n_splits if n_splits > 1 else int(valid_size * len(o)) if isinstance(valid_size, float) else valid_size\n",
    "        if test_size: \n",
    "            ts = int(test_size * len(o)) if isinstance(test_size, float) else test_size\n",
    "            train_valid, test = train_test_split(range(len(o)), test_size=ts, stratify=o if stratify_ else None, shuffle=shuffle, \n",
    "                                                 random_state=random_state, **kwargs)\n",
    "            test = toL(test)\n",
    "            if shuffle: test = random_shuffle(test, random_state)\n",
    "            if vs == 0:\n",
    "                train, _ = RandomSplitter(0, seed=random_state)(o[train_valid])\n",
    "                train = toL(train)\n",
    "                if balance: train = train[balance_idx(o[train], random_state=random_state)]\n",
    "                if shuffle: train = random_shuffle(train, random_state)\n",
    "                train_ = L(L([train]) * n_splits) if n_splits > 1 else train\n",
    "                valid_ = L(L([train]) * n_splits) if n_splits > 1 else train\n",
    "                test_ = L(L([test]) * n_splits) if n_splits > 1 else test\n",
    "                if n_splits > 1: \n",
    "                    return [split for split in itemify(train_, valid_, test_)]\n",
    "                else: \n",
    "                    return train_, valid_, test_\n",
    "            elif n_splits > 1: \n",
    "                if stratify_: \n",
    "                    splits = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state).split(np.arange(len(train_valid)), o[train_valid])\n",
    "                else:\n",
    "                    splits = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state).split(np.arange(len(train_valid)))\n",
    "                train_, valid_ = L([]), L([])\n",
    "                for train, valid in splits:\n",
    "                    train, valid = toL(train), toL(valid)\n",
    "                    if balance: train = train[balance_idx(o[train], random_state=random_state)]\n",
    "                    if shuffle: \n",
    "                        train = random_shuffle(train, random_state)\n",
    "                        valid = random_shuffle(valid, random_state)\n",
    "                    train_.append(L(L(train_valid)[train]))\n",
    "                    valid_.append(L(L(train_valid)[valid]))\n",
    "                test_ = L(L([test]) * n_splits)\n",
    "                return [split for split in itemify(train_, valid_, test_)]\n",
    "            else:\n",
    "                train, valid = train_test_split(range(len(train_valid)), test_size=vs, random_state=random_state, \n",
    "                                                stratify=o[train_valid] if stratify_ else None, shuffle=shuffle, **kwargs)\n",
    "                train, valid = toL(train), toL(valid)\n",
    "                if balance: train = train[balance_idx(o[train], random_state=random_state)]\n",
    "                if shuffle: \n",
    "                    train = random_shuffle(train, random_state)\n",
    "                    valid = random_shuffle(valid, random_state)\n",
    "                return (L(L(train_valid)[train]), L(L(train_valid)[valid]),  test)\n",
    "        else: \n",
    "            if vs == 0:\n",
    "                train, _ = RandomSplitter(0, seed=random_state)(o)\n",
    "                train = toL(train)\n",
    "                if balance: train = train[balance_idx(o[train], random_state=random_state)]\n",
    "                if shuffle: train = random_shuffle(train, random_state)\n",
    "                train_ = L(L([train]) * n_splits) if n_splits > 1 else train\n",
    "                valid_ = L(L([train]) * n_splits) if n_splits > 1 else train\n",
    "                if n_splits > 1: \n",
    "                    return [split for split in itemify(train_, valid_)]\n",
    "                else: \n",
    "                    return (train_, valid_)\n",
    "            elif n_splits > 1: \n",
    "                if stratify_: splits = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state).split(np.arange(len(o)), o)\n",
    "                else: splits = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state).split(np.arange(len(o)))\n",
    "                train_, valid_ = L([]), L([])\n",
    "                for train, valid in splits:\n",
    "                    train, valid = toL(train), toL(valid)\n",
    "                    if balance: train = train[balance_idx(o[train], random_state=random_state)]\n",
    "                    if shuffle: \n",
    "                        train = random_shuffle(train, random_state)\n",
    "                        valid = random_shuffle(valid, random_state)\n",
    "                    if not isinstance(train, (list, L)):  train = train.tolist()\n",
    "                    if not isinstance(valid, (list, L)):  valid = valid.tolist()\n",
    "                    train_.append(L(train))\n",
    "                    valid_.append(L(L(valid)))\n",
    "                return [split for split in itemify(train_, valid_)]\n",
    "            else:\n",
    "                train, valid = train_test_split(range(len(o)), test_size=vs, random_state=random_state, stratify=o if stratify_ else None, \n",
    "                                                shuffle=shuffle, **kwargs)\n",
    "                train, valid = toL(train), toL(valid)\n",
    "                if balance: train = train[balance_idx(o[train], random_state=random_state)]\n",
    "                return train, valid\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_splits(o, n_splits:int=1, valid_size:float=0.2, test_size:float=0., train_only:bool=False, train_perc:float=1., balance:bool=False,\n",
    "               shuffle:bool=True, stratify:bool=True, check_splits:bool=True, random_state:Union[None, int]=None, verbose:bool=False):\n",
    "    '''Arguments: \n",
    "        o            : object to which splits will be applied, usually target.\n",
    "        n_splits     : number of folds. Must be an int >= 1.\n",
    "        valid_size   : size of validation set. Only used if n_splits = 1. If n_splits > 1 valid_size = (1. - test_size) / n_splits. \n",
    "        test_size    : size of test set. Default = 0.\n",
    "        train_only   : if True valid set == train set. This may be useful for debugging purposes.\n",
    "        train_perc   : percentage of the train set used. Default = 1. Useful for to get learning curves with different train sizes.\n",
    "        balance      : whether to balance data so that train always contain the same number of items per class.\n",
    "        shuffle      : whether to shuffle data before splitting into batches. Note that the samples within each split will be shuffle.\n",
    "        stratify     : whether to create folds preserving the percentage of samples for each class.\n",
    "        check_splits : whether to perform leakage and completion checks.\n",
    "        random_state : when shuffle is True, random_state affects the ordering of the indices. Pass an int for reproducible output.\n",
    "    '''\n",
    "    if n_splits == 1 and valid_size == 0. and  test_size == 0.: train_only = True\n",
    "    if balance: stratify = True\n",
    "    splits = TrainValidTestSplitter(n_splits, valid_size=valid_size, test_size=test_size, train_only=train_only, stratify=stratify, \n",
    "                                      balance=balance, shuffle=shuffle, random_state=random_state, verbose=verbose)(o)\n",
    "    if check_splits:\n",
    "        if train_only or (n_splits == 1 and valid_size == 0): print('valid == train')\n",
    "        elif n_splits > 1: \n",
    "            for i in range(n_splits): \n",
    "                leakage_finder([*splits[i]], verbose=True)\n",
    "                cum_len = 0\n",
    "                for split in splits[i]: cum_len += len(split)\n",
    "                if not balance: assert len(o) == cum_len, f'len(o)={len(o)} while cum_len={cum_len}'\n",
    "        else: \n",
    "            leakage_finder([splits], verbose=True)\n",
    "            cum_len = 0\n",
    "            if not isinstance(splits[0], Integral):\n",
    "                for split in splits: cum_len += len(split)\n",
    "            else: cum_len += len(splits)\n",
    "            if not balance: assert len(o) == cum_len, f'len(o)={len(o)} while cum_len={cum_len}'\n",
    "    if train_perc and train_perc > 0 and train_perc < 1: \n",
    "        if n_splits > 1:\n",
    "            splits = list(splits)\n",
    "            for i in range(n_splits): \n",
    "                splits[i] = list(splits[i])\n",
    "                splits[i][0] = L(np.random.choice(splits[i][0], int(len(splits[i][0]) * train_perc), False).tolist())\n",
    "                if train_only:\n",
    "                    if valid_size != 0: splits[i][1] = splits[i][0]\n",
    "                    if test_size != 0: splits[i][2] = splits[i][0]\n",
    "                splits[i] = tuple(splits[i])\n",
    "            splits = tuple(splits)\n",
    "        else: \n",
    "            splits = list(splits)\n",
    "            splits[0] = L(np.random.choice(splits[0], int(len(splits[0]) * train_perc), False).tolist())\n",
    "            if train_only:\n",
    "                if valid_size != 0: splits[1] = splits[0]\n",
    "                if test_size != 0: splits[2] = splits[0]\n",
    "            splits = tuple(splits)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#636) [22,228,36,171,634,568,114,120,540,300...],\n",
       " (#200) [451,506,188,3,623,183,478,632,551,590...],\n",
       " (#200) [25,344,940,408,807,376,223,289,229,125...])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_splits                = 1\n",
    "\n",
    "cv                      = True\n",
    "valid_size              = 0.2\n",
    "test_size               = 0.2\n",
    "train_only              = False  # set to True for debugging (valid = train)\n",
    "train_perc              = 1.\n",
    "stratify                = True\n",
    "balance                 = True\n",
    "shuffle                 = True\n",
    "predefined_splits       = None\n",
    "\n",
    "\n",
    "check_splits = True\n",
    "random_state = 23\n",
    "\n",
    "y = np.random.randint(0, 3, 1000) + 100\n",
    "\n",
    "splits = get_splits(y, n_splits=n_splits, valid_size=valid_size, test_size=test_size, shuffle=shuffle, balance=balance, stratify=stratify,\n",
    "                    train_only=train_only, train_perc=train_perc, check_splits=check_splits, random_state=random_state, verbose=True)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def TimeSplitter(valid_pct=0.2):\n",
    "    \"Create function that splits `items` between train/val with `valid_pct` without shuffling data.\"\n",
    "    def _inner(o):\n",
    "        cut = int(valid_pct * len(o))\n",
    "        idx = np.arange(len(o))\n",
    "        return L(idx[:-cut].tolist()), L(idx[-cut:].tolist())\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#800) [0,1,2,3,4,5,6,7,8,9...],\n",
       " (#200) [800,801,802,803,804,805,806,807,808,809...])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.arange(1000) + 100\n",
    "test_eq(TimeSplitter(valid_pct=0.2)(y)[1], L(np.arange(800, 1000).tolist()))\n",
    "TimeSplitter(valid_pct=0.2)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stratify set to False as n_splits=5 cannot be greater than the min number of members in each class (1).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(601.11, (#800) [314,194,782,789,502,917,137,415,904,181...])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_splits                = 5\n",
    "\n",
    "cv                      = True\n",
    "valid_size              = 0.2  \n",
    "test_size               = 0\n",
    "train_only              = False  # set to True for debugging (valid = train)\n",
    "train_perc              = 1.\n",
    "stratify                = True\n",
    "balance                 = True\n",
    "shuffle                 = True\n",
    "predefined_splits       = None\n",
    "\n",
    "\n",
    "check_splits = True\n",
    "random_state = 23\n",
    "\n",
    "splits = get_splits(y, n_splits=n_splits, valid_size=valid_size, test_size=test_size, shuffle=shuffle, balance=balance, stratify=stratify,\n",
    "                    train_only=train_only, train_perc=train_perc, check_splits=check_splits, random_state=random_state, verbose=True)\n",
    "split = splits[0] if n_splits == 1 else splits[0][0]\n",
    "y[split].mean(), split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((#800) [314,194,782,789,502,917,137,415,904,181...],\n",
       "  (#200) [362,151,934,378,95,597,500,117,980,844...]),\n",
       " ((#800) [312,198,777,788,515,910,145,413,898,186...],\n",
       "  (#200) [352,133,955,396,64,596,442,79,991,882...]),\n",
       " ((#800) [311,197,783,791,507,922,145,416,908,184...],\n",
       "  (#200) [338,125,912,361,54,594,486,88,994,859...]),\n",
       " ((#800) [296,181,782,789,493,917,130,401,905,165...],\n",
       "  (#200) [405,199,953,444,113,610,515,137,997,881...]),\n",
       " ((#800) [320,190,782,788,506,906,141,412,893,178...],\n",
       "  (#200) [336,149,942,358,49,582,472,70,990,907...])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list([splits[0], splits[1], splits[2], splits[3], splits[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stratify set to False as n_splits=5 cannot be greater than the min number of members in each class (1).\n",
      "valid == train\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "valid_size = 0.\n",
    "test_size = 0.\n",
    "shuffle = True\n",
    "stratify = True\n",
    "train_only = True\n",
    "train_perc = 1.\n",
    "check_splits = True\n",
    "random_state = 1\n",
    "\n",
    "splits = get_splits(y, n_splits=n_splits, valid_size=valid_size, test_size=test_size, shuffle=shuffle, stratify=stratify,\n",
    "                    train_only=train_only, train_perc=train_perc, check_splits=check_splits, random_state=random_state, verbose=True)\n",
    "for split in splits: \n",
    "    test_eq(len(split[0]), len(y))\n",
    "    test_eq(np.sort(split[0]), np.arange(len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "y = np.random.randint(0, 2, 1000)\n",
    "\n",
    "splits = get_splits(y, n_splits=n_splits, shuffle=False, check_splits=True)\n",
    "test_eq(np.concatenate((L(zip(*splits))[1])), np.arange(len(y)))\n",
    "\n",
    "splits = get_splits(y, n_splits=n_splits, shuffle=True, check_splits=True)\n",
    "test_eq(np.sort(np.concatenate((L(zip(*splits))[1]))), np.arange(len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 2\n",
    "y = np.random.randint(0, 2, 1000)\n",
    "\n",
    "splits = get_splits(y, n_splits=n_splits, test_size=0.2, shuffle=False)\n",
    "for i in range(n_splits): leakage_finder(*splits[i])\n",
    "test_eq(len(splits), n_splits)\n",
    "test_eq(len(splits[0]), 3)\n",
    "s = []\n",
    "[s.extend(split) for split in splits[0]]\n",
    "test_eq(np.sort(s), np.arange(len(y)))\n",
    "s = []\n",
    "[s.extend(split) for split in splits[1]]\n",
    "test_eq(np.sort(s), np.arange(len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.randint(0, 2, 1000)\n",
    "splits1 = get_splits(y, valid_size=.25, test_size=0, random_state=23, stratify=True, shuffle=True)\n",
    "splits2 = get_splits(y, valid_size=.25, test_size=0, random_state=23, stratify=True, shuffle=True)\n",
    "splits3 = get_splits(y, valid_size=.25, test_size=0, random_state=None, stratify=True, shuffle=True)\n",
    "splits4 = get_splits(y, valid_size=.25, test_size=0, random_state=None, stratify=True, shuffle=True)\n",
    "test_eq(splits1[0], splits2[0])\n",
    "test_ne(splits3[0], splits4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.randint(0, 2, 100)\n",
    "splits = get_splits(y, valid_size=.25, test_size=0, random_state=23, stratify=True, shuffle=True)\n",
    "test_eq(len(splits), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.randint(0, 2, 100)\n",
    "splits = get_splits(y, valid_size=.25, test_size=0, random_state=23, stratify=True)\n",
    "test_eq(len(splits), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.randint(0, 2, 100)\n",
    "splits = get_splits(y, valid_size=.25, test_size=20, random_state=23, stratify=True)\n",
    "test_eq(len(splits), 3)\n",
    "leakage_finder(*splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = TrainValidTestSplitter(valid_size=.25, test_size=20, random_state=23, stratify=True)(np.random.randint(0, 2, 100))\n",
    "test_eq(len(splits[1]), 25)\n",
    "test_eq(len(splits[2]), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = np.random.randint(0, 2, 1000)\n",
    "for p in [1, .75, .5, .25, .125]:\n",
    "    splits = get_splits(o, train_perc=p)\n",
    "    test_eq(len(splits[0]), len(o) * .8 * p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#60) [32,61,3,10,84,81,82,68,29,48...],\n",
       " (#20) [94,31,66,72,22,46,64,25,85,34...],\n",
       " (#20) [75,36,17,42,41,47,13,54,37,9...])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = L([0] * 50 + [1] * 25 + [2] * 15 + [3] * 10)\n",
    "splits = get_splits(y, valid_size=.2, test_size=.2)\n",
    "test_eq(np.mean(y[splits[0]])==np.mean(y[splits[1]])==np.mean(y[splits[2]]), True)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#60) [0,1,2,3,4,5,6,7,8,9...],\n",
       " (#20) [60,61,62,63,64,65,66,67,68,69...],\n",
       " (#20) [80,81,82,83,84,85,86,87,88,89...])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = L([0] * 50 + [1] * 25 + [2] * 15 + [3] * 10)\n",
    "splits = get_splits(y, n_splits=1, valid_size=.2, test_size=.2, shuffle=False)\n",
    "# test_eq(splits[0] + splits[1] + splits[2], np.arange(100))\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = get_splits(np.random.randint(0,5,100), valid_size=0.213, test_size=17)\n",
    "test_eq(len(splits[1]), 21)\n",
    "test_eq(len(splits[2]), 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#12) [80,90,71,89,49,78,63,91,24,17...],\n",
       " (#21) [37,41,92,65,87,43,57,56,14,27...],\n",
       " (#17) [84,99,73,19,51,96,62,8,60,26...])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = get_splits(np.random.randint(0,5,100), valid_size=0.213, test_size=17, train_perc=.2)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_predefined_splits(*xs):\n",
    "    '''xs is a list with X_train, X_valid, ...'''\n",
    "    splits_ = []\n",
    "    start = 0\n",
    "    for x in xs: \n",
    "        splits_.append(L(list(np.arange(start, start + len(x)))))\n",
    "        start += len(x)\n",
    "    return tuple(splits_)\n",
    "\n",
    "def combine_split_data(xs, ys=None):\n",
    "    '''xs is a list with X_train, X_valid, .... ys is None or a list with y_train, y_valid, .... '''\n",
    "    xs = [to3d(x) for x in xs]\n",
    "    splits = get_predefined_splits(*xs)\n",
    "    if ys is None: return concat(*xs), None, splits\n",
    "    else: return concat(*xs), concat(*ys), splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = np.random.rand(3,3,4), np.random.randint(0,2,3), np.random.rand(2,3,4), np.random.randint(0,2,2)\n",
    "X, y, splits = combine_split_data([X_train, X_valid], [y_train, y_valid])\n",
    "test_eq(X_train, X[splits[0]])\n",
    "test_eq(X_valid, X[splits[1]])\n",
    "test_type(X_train, X)\n",
    "test_type(y_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = np.random.rand(3,4), np.random.randint(0,2,3), np.random.rand(2,4), np.random.randint(0,2,2)\n",
    "X, y, splits = combine_split_data([X_train, X_valid], [y_train, y_valid])\n",
    "test_eq(X_train[:, None], X[splits[0]])\n",
    "test_eq(X_valid[:, None], X[splits[1]])\n",
    "test_type(X_train, X)\n",
    "test_type(y_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 000_utils.ipynb.\n",
      "Converted 000b_data.validation.ipynb.\n",
      "Converted 000c_data.preparation.ipynb.\n",
      "Converted 001_data.external.ipynb.\n",
      "Converted 002_data.core.ipynb.\n",
      "Converted 003_data.preprocessing.ipynb.\n",
      "Converted 003b_data.transforms.ipynb.\n",
      "Converted 003c_data.mixed_augmentation.ipynb.\n",
      "Converted 003d_data.image.ipynb.\n",
      "Converted 005_data.tabular.ipynb.\n",
      "Converted 006_data.mixed.ipynb.\n",
      "Converted 007_metrics.ipynb.\n",
      "Converted 008_learner.ipynb.\n",
      "Converted 009_optimizer.ipynb.\n",
      "Converted 010_callback.core.ipynb.\n",
      "Converted 011_callback.semi_supervised.ipynb.\n",
      "Converted 100_models.utils.ipynb.\n",
      "Converted 100b_models.layers.ipynb.\n",
      "Converted 100c_models.explainability.ipynb.\n",
      "Converted 101_models.ResNet.ipynb.\n",
      "Converted 101b_models.ResNetPlus.ipynb.\n",
      "Converted 102_models.InceptionTime.ipynb.\n",
      "Converted 102b_models.InceptionTimePlus.ipynb.\n",
      "Converted 103_models.MLP.ipynb.\n",
      "Converted 103b_models.FCN.ipynb.\n",
      "Converted 103c_models.FCNPlus.ipynb.\n",
      "Converted 104_models.ResCNN.ipynb.\n",
      "Converted 105_models.RNN.ipynb.\n",
      "Converted 105_models.RNNPlus.ipynb.\n",
      "Converted 106_models.XceptionTime.ipynb.\n",
      "Converted 106b_models.XceptionTimePlus.ipynb.\n",
      "Converted 107_models.RNN_FCN.ipynb.\n",
      "Converted 107b_models.RNN_FCNPlus.ipynb.\n",
      "Converted 108_models.TransformerModel.ipynb.\n",
      "Converted 108b_models.TST.ipynb.\n",
      "Converted 108c_models.TSTPlus.ipynb.\n",
      "Converted 109_models.OmniScaleCNN.ipynb.\n",
      "Converted 110_models.mWDN.ipynb.\n",
      "Converted 111_models.ROCKET.ipynb.\n",
      "Converted 112_models.XResNet1d.ipynb.\n",
      "Converted 112b_models.XResNet1dPlus.ipynb.\n",
      "Converted 113_models.TCN.ipynb.\n",
      "Converted 114_models.XCM.ipynb.\n",
      "Converted 120_models.TabModel.ipynb.\n",
      "Converted 130_models.MultiInputNet.ipynb.\n",
      "Converted 900_tutorials.ipynb.\n",
      "Converted index.ipynb.\n",
      "\n",
      "\n",
      "Checking folder: /Users/nacho/Documents/Machine_Learning/Jupyter_Notebooks/tsai/tsai\n",
      "Correct conversion! ðŸ˜ƒ\n",
      "Total time elapsed 193 s\n",
      "Tuesday 12/01/20 21:02:54 CET\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "out = create_scripts(); beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
