{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp callback.gblend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Blending\n",
    "\n",
    "> Callback used to apply gradient blending to multi-modal models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an unofficial PyTorch implementation by Ignacio Oguiza (timeseriesAI@gmail.com) based on: Wang, W., Tran, D., & Feiszli, M. (2020). **What Makes Training Multi-Modal Classification Networks Hard?**. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 12695-12705)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.callback.all import *\n",
    "from tsai.imports import *\n",
    "from tsai.utils import *\n",
    "from tsai.data.preprocessing import *\n",
    "from tsai.data.transforms import *\n",
    "from tsai.models.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GBlendLoss(Module):\n",
    "    \"Wrapper loss used by the gradient blending callback to allow weights applied to each modality.\"\n",
    "\n",
    "    def __init__(self, crit=None, w=None):\n",
    "        self.crit = ifnone(crit, CrossEntropyLossFlat())\n",
    "        self.w = w\n",
    "        \n",
    "    def forward(self, preds, target):\n",
    "        # unweighted loss\n",
    "        if not is_listy(preds): return self.crit(preds, target)\n",
    "        \n",
    "        # weighted loss\n",
    "        if self.w is None: self.w = tensor([1.] * len(preds))\n",
    "        loss = 0\n",
    "        for i, pred in enumerate(preds): loss += self.crit(pred, target) * self.w[i]\n",
    "        return loss / sum(self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class GBlend(Callback):\n",
    "    r\"\"\"A callback to implement multi-modal gradient blending.\n",
    "    \n",
    "    This is an unofficial PyTorch implementation by Ignacio Oguiza of  - oguiza@gmail.com based on: Wang, W., Tran, D., & Feiszli, M. (2020). \n",
    "    What Makes Training Multi-Modal Classification Networks Hard?. In Proceedings of the IEEE/CVF Conference on Computer Vision and \n",
    "    Pattern Recognition (pp. 12695-12705).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, V_pct=.1, n:Union[None, int, tuple, list]=(10, 5), sel_metric:Optional[str]=None, show_plot:bool=False, path:str='./data/gblend'): \n",
    "        \n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            V_pct      : subset of train where OGR will be measured (to estimate L*)\n",
    "            n          : None: offline learning, int: super-epoch (online learning), tuple: (warmup super-epoch, super-epoch)(online learning with warm up)\n",
    "            sel_metric : which metric will be used to calculate overfitting and generalization during training. If None, loss will be used.\n",
    "            show_plot  : will show a plot with the wieghts at the end of training\n",
    "        \"\"\"\n",
    "        assert V_pct < 1, 'V_pct must be < 1'\n",
    "        self.V_pct, self.n, self.sel_metric, self.show_plot = V_pct, n, sel_metric, show_plot\n",
    "        self.metric_idx = None\n",
    "        self.path = Path(path)\n",
    "        if not os.path.exists(self.path): os.makedirs(self.path)\n",
    "\n",
    "    def before_fit(self):\n",
    "        \n",
    "        # model\n",
    "        self.M = self.model.M \n",
    "        self.old_multi_output = self.learn.model.multi_output\n",
    "        self.learn.model.multi_output = True\n",
    "\n",
    "        #loss\n",
    "        if cls_name(self.learn.loss_func) != 'GBlendLoss': self.learn.loss_func = GBlendLoss(crit=self.learn.loss_func)\n",
    "\n",
    "        # calculate super_epochs\n",
    "        if self.n is None: \n",
    "            self.super_epochs = [0]\n",
    "        else: \n",
    "            if is_listy(self.n): \n",
    "                self.wu_n = self.n[0]\n",
    "                self.n = self.n[1]\n",
    "            else: \n",
    "                self.wu_n = self.n\n",
    "            rng = range(int(max(0, self.n_epoch - self.wu_n) / self.n + 1))\n",
    "            self.super_epochs = []\n",
    "            for i in rng: \n",
    "                self.super_epochs.append((i * self.wu_n) if i <= 1 else int((i + self.wu_n / self.n - 1) * self.n))\n",
    "        self.super_epochs.append(self.n_epoch)\n",
    "        \n",
    "        # create T'(Tp) and V dataloaders\n",
    "        n_out = len(self.learn.dls.train.dataset.ptls) - self.learn.dls.train.dataset.n_inp\n",
    "        train_targets = self.learn.dls.train.dataset.ptls[-n_out]\n",
    "        Tp_idx, V_idx = get_splits(train_targets, valid_size=self.V_pct)\n",
    "        _Tp_train_dls = []\n",
    "        _V_train_dls = []\n",
    "        self.learn.new_dls = []\n",
    "        for dl in self.learn.dls[0].loaders: # train MixedDataLoaders\n",
    "            _Tp_dl = get_subset_dl(dl, Tp_idx)\n",
    "            _V_dl = get_subset_dl(dl, V_idx)\n",
    "            _Tp_train_dls.append(_Tp_dl)\n",
    "            _V_train_dls.append(_V_dl) \n",
    "            self.learn.new_dls.append(DataLoaders(_Tp_dl, _V_dl, device=self.learn.dls.device))\n",
    "        self.learn.new_dls.append(MixedDataLoaders(MixedDataLoader(*_Tp_train_dls, shuffle=True),  # train - train\n",
    "                                                   MixedDataLoader(*_V_train_dls, shuffle=False),  # train - valid\n",
    "                                                   device=self.learn.dls.device))\n",
    "        \n",
    "        # prepare containers\n",
    "        self.learn.LT = []\n",
    "        self.learn.LV = []\n",
    "\n",
    "    def before_train(self):\n",
    "        if self.epoch in self.super_epochs[:-1] and not 'LRFinder' in [cls_name(cb) for cb in self.learn.cbs]: \n",
    "            self.train_epochs = np.diff(self.super_epochs)[self.super_epochs.index(self.epoch)]\n",
    "            \n",
    "            #compute weights\n",
    "            self.learn.save('gblend_learner')\n",
    "            torch.save(self.learn.model, self.path/'gblend_model')\n",
    "            w = self.compute_weights()\n",
    "            if self.epoch == 0: self.learn.ws = [w]\n",
    "            else: self.learn.ws.append(w)\n",
    "            self.learn = self.learn.load('gblend_learner')\n",
    "            self.learn.loss_func.w = w\n",
    "\n",
    "    def compute_weights(self):\n",
    "\n",
    "        # _LT0 = []\n",
    "        # _LV0 = []\n",
    "        _LT = []\n",
    "        _LV = []\n",
    "        for i in range(self.M + 1):            \n",
    "            model = torch.load(self.path/'gblend_model')\n",
    "            learn = Learner(self.learn.new_dls[i], model.m[i], loss_func=GBlendLoss(), \n",
    "                            opt_func=self.learn.opt_func, metrics=self.learn.metrics)\n",
    "            learn.model.multi_output = False\n",
    "            learn.remove_cbs(learn.cbs[1])\n",
    "            learn.add_cb(Recorder(train_metrics=True))\n",
    "            with learn.no_bar():\n",
    "                with learn.no_logging(): \n",
    "                    learn.fit_one_cycle(self.train_epochs, pct_start=0)\n",
    "            if self.metric_idx is None and self.sel_metric is not None:\n",
    "                metric_names = learn.recorder.metric_names[1:-1]\n",
    "                self.metric_idx = [i for i,m in enumerate(metric_names) if self.sel_metric in m]\n",
    "            else: self.metric_idx = [0, 1]\n",
    "            metric_values = learn.recorder.values[-1][self.metric_idx]\n",
    "            _LT.append(metric_values[0])\n",
    "            _LV.append(metric_values[1])\n",
    "\n",
    "        # if self.epoch == 0: self.compute_previous_metrics()\n",
    "        self.compute_previous_metrics()\n",
    "        self.learn.LT.append(_LT)\n",
    "        self.learn.LV.append(_LV)\n",
    "\n",
    "        LT1 = array(self.learn.LT[-2])\n",
    "        LT2 = array(self.learn.LT[-1])\n",
    "        LV1 = array(self.learn.LV[-2])\n",
    "        LV2 = array(self.learn.LV[-1])\n",
    "\n",
    "        ΔG = (LV1 - LV2) if self.metric_idx[0] == 0 else (LV2 - LV1)\n",
    "        O1 = (LV1 - LT1) if self.metric_idx[0] == 0 else (LT1 - LV1)\n",
    "        O2 = (LV2 - LT2) if self.metric_idx[0] == 0 else (LT2 - LV2)\n",
    "\n",
    "        ΔG = np.maximum(0, ΔG)\n",
    "\n",
    "        ΔO = O2 - O1\n",
    "        ΔO2 = np.maximum(1e-8, (O2 - O1)**2)\n",
    "        w = np.maximum(1e-8, np.nan_to_num(ΔG / ΔO2))\n",
    "        w = w / w.sum()\n",
    "        w = w.tolist()\n",
    "        return w\n",
    "\n",
    "    def compute_previous_metrics(self):\n",
    "        if self.metric_idx[0] == 0:  metric = self.loss_func\n",
    "        else: metric = self.learn.metrics[(min(array(self.metric_idx) - 2) - 1) // 2]\n",
    "        _LT = []\n",
    "        _LV = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(self.M + 1):\n",
    "                model = torch.load(self.path/'gblend_model')\n",
    "                model.multi_output = False\n",
    "                model = model.m[i]\n",
    "                _train_metrics = []\n",
    "                _valid_metrics = []\n",
    "                for j,dl in enumerate(self.learn.new_dls[i]):\n",
    "                    it = iter(dl)\n",
    "                    _preds = []\n",
    "                    _targets = []\n",
    "                    for b in it: \n",
    "                        _preds.extend(model(*b[:-1]))\n",
    "                        _targets.extend(b[-1])\n",
    "                    _preds, _targets = stack(_preds), stack(_targets)\n",
    "                    try: _metric_values = metric(_preds, _targets).cpu().item()\n",
    "                    except: _metric_values = metric(torch.argmax(_preds, 1), _targets).cpu().item()\n",
    "                    if j == 0: _LT.append(_metric_values)\n",
    "                    else: _LV.append(_metric_values)\n",
    "            self.learn.LT.append(_LT)\n",
    "            self.learn.LV.append(_LV)\n",
    "\n",
    "    def after_fit(self):\n",
    "        if hasattr(self.learn, \"ws\") and self.show_plot:\n",
    "            widths = np.diff(self.super_epochs)\n",
    "            cum_ws = 0\n",
    "            for i in range(self.M + 1):\n",
    "                plt.bar(self.super_epochs[:-1] + widths/2, stack(self.learn.ws)[:, i], bottom=cum_ws, width=widths, \n",
    "                        label=f'k={i+1}' if i < self.M else f'fused')\n",
    "                cum_ws += stack(self.learn.ws)[:, i]\n",
    "            plt.xlim(0, self.super_epochs[-1])\n",
    "            plt.ylim(0, 1)\n",
    "            plt.xticks(self.super_epochs)\n",
    "            plt.legend(loc='best')\n",
    "            plt.title('Online G-Blend Weights by modality')\n",
    "            plt.show()\n",
    "\n",
    "        self.learn.model.multi_output = self.old_multi_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import *\n",
    "from tsai.data.all import *\n",
    "from tsai.models.utils import *\n",
    "from tsai.models.XCM import *\n",
    "from tsai.models.TabModel import *\n",
    "from tsai.models.MultiInputNet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.37it/s]\n"
     ]
    }
   ],
   "source": [
    "dsid = 'NATOPS'\n",
    "X, y, splits = get_UCR_data(dsid, split_data=False)\n",
    "ts_features_df = get_ts_features(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nacho/anaconda3/lib/python3.7/site-packages/fastai/callback/core.py:50: UserWarning: You are shadowing an attribute (M) that exists in the learner. Use `self.learn.M` to avoid this\n",
      "  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x36 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.841828</td>\n",
       "      <td>1.709158</td>\n",
       "      <td>0.427778</td>\n",
       "      <td>0.685815</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# raw ts\n",
    "tfms  = [None, [Categorize()]]\n",
    "batch_tfms = TSStandardize()\n",
    "ts_dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)\n",
    "ts_model = build_ts_model(XCM, dls=ts_dls, window_perc=.5)\n",
    "\n",
    "# ts features\n",
    "cat_names = None\n",
    "cont_names = ts_features_df.columns[:-2]\n",
    "y_names = 'target'\n",
    "tab_dls = get_tabular_dls(ts_features_df, cat_names=cat_names, cont_names=cont_names, y_names=y_names, splits=splits)\n",
    "tab_model = build_tabular_model(TabModel, dls=tab_dls)\n",
    "\n",
    "# mixed\n",
    "mixed_dls = get_mixed_dls(ts_dls, tab_dls)\n",
    "MultiModalNet = MultiInputNet(ts_model, tab_model, c_out=mixed_dls.c)\n",
    "gblend = GBlend(V_pct=.5, n=(10, 5), sel_metric=None)\n",
    "learn = Learner(mixed_dls, MultiModalNet, metrics=[accuracy, RocAuc()], cbs=gblend)\n",
    "learn.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "out = create_scripts(); beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
